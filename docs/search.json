[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "",
    "text": "Prefacio\nEste libro trata sobre la enseñanza de algunos métodos básicos de la estadística y la moderna ciencia de datos y su aplicación al entorno industrial. Está concebido de forma práctica con multitud de ejemplos, no sólo industriales, con el objetivo de mostrar los métodos cuantitativos de análisis, y también el razonamiento necesario para dar sentido a los resultados presentados por las herramientas de análisis de datos.\nEl objetivo del libro es acercar a los estudiantes de la Formación Profesional al uso de las herramientas de análisis de datos industriales. El entorno de la industria actual produce un enorme y constante flujo de datos como resultado tanto de la implantación de sistemas de captura automáticos como del aumento de la tecnificación de los puestos de trabajo; se requiere por parte de los profesionales industriales que sean capaces de analizar esta enorme cantidad de datos para transformarlos en información para la decisión. En la empresa industrial actual, son los ingenieros y técnicos de planta, y no estadísticos o ingenieros informáticos, quienes participan diariamente en la presentacion y discusion de los datos y en la toma de decisiones operativas, tanto en los equipos de trabajo como ante la Dirección. Por esta razón, considero necesario proporcionar a los estudiantes de la Formación Profesional un conocimiento básico de los conceptos, herramientas y métodos del análisis de datos, así como de algunas técnicas de presentación y comunicación de la información.\nEl control estadístico de la calidad empezó con W.E. Deming a mediados del pasado siglo XX, y fueron las empresas japonesas, sobre todo las automovilísticas, las que inicialmente recogieron el testigo de Deming y aplicaron estos principios a la mejora de la producción industrial, difundiendo su conocimiento a todos los niveles jerárquicos de las organizaciones, desde los operarios de línea hasta los más altos directivos. Desde ese momento hasta la difusión actual de los métodos Six Sigma gracias a General Electric y Motorola, la mejora industrial de los procesos ha estado siempre apoyada en la correcta utilización de estas metodologías.\nLa enseñanza de los conceptos estadísticos ha estado, casi siempre, a cargo de profesores con una gran formación en matemáticas. Estos profesores suelen identificar la comprensión de los conceptos estadísticos con su comprensión matemática. Sin embargo, cuando enseñamos estadística industrial, debemos hacer énfasis tanto en las ideas y la comprensión de los conceptos como en su utilización práctica, y reconocer que el razonamiento matemático no es el único camino para la comprensión conceptual.\nLa práctica de la estadística requiere buen juicio y sentido común. Dado que el buen juicio se desarrolla con la experiencia, un curso de iniciación debe presentar unas guías claras de aplicación de los métodos, y no dar por supuestas unas exigencias excesivamente altas sobre la capacidad de juicio analítico de los estudiantes; no sería un planteamiento razonable. Con el fin de desarrollar esta capacidad de juicio analítico he introducido explicaciones detalladas en la mayor parte de los ejemplos. En todos los casos, los ejercicios requerirán del estudiante no sólo una resolución numérica, sino el uso del juicio analítico y la explicación verbal (o escrita) de las decisiones tomadas y conclusiones realizadas. Creo que este planteamiento será mucho más beneficioso a largo plazo que limitarse a una simple resolución numérica.\nMi experiencia industrial me ha mostrado que en las situaciones reales, sobre el terreno, la comprensión práctica de los conceptos es más importante que su rigurosa formulación matemática. Por esta razón, en el desarrollo del contenido del libro he insistido más en la forma de aplicar las herramientas y entender los análisis que en el conocimiento formal de las fórmulas estadísticas y su deducción matemática. He hecho especial hincapié en la utilización de herramientas sencillas, sobre todo gráficas, que casi siempre son una ayuda para comprender la información contenida en un conjunto de datos. El objetivo es proporcionar al estudiante las bases de la metodología del análisis de datos y del análisis estadístico, y cómo puede aplicarse a la resolución de problemas técnicos concretos, más que el conocimiento de la teoría matemática de la estadística.\nHe evitado las explicaciones formales sobre temas estadísticos cuando no son indispensables para su aplicación práctica. Así, por ejemplo, al explicar la media de un conjunto de datos considero más importante entender el concepto físico de “centro de gravedad” que los conceptos estadísticos de esperanza matemática, que no se tocan en este texto. En este sentido, he intentado que el alumno aprenda a diferenciar “en qué consiste” un estadístico, de “cómo se calcula”. Comprender la diferencia entre el concepto y su fórmula de cálculo es fundamental para entender en qué situación debe usarse uno u otro estadístico.\nUn curso de introducción a la estadística y análisis de datos industriales debe ser, ante todo, práctico y orientado a su aplicación en el entorno industrial real. Los principales temas de trabajo estadístico en la industria tienen que ver con la captura de datos, su almacenamiento y su depuración, su descripción utilizando gráficos, la inferencia (intervalos de confianza y tests), la construcción de modelos explicativos, el diseño de los experimentos industriales, el control estadístico de la calidad y la exposición y presentación de resultados. Dado el alcance limitado de este libro, algunos de estos temas se tratarán de forma muy ligera, y necesitarán de un estudio posterior si el alumno tiene interés en profundizar en ellos. A pesar de que los temas más especializados puedan ser importantes en algunas aplicaciones específicas, no preparan al estudiante para lo que se va a encontrar en el terreno en la mayor parte de las ocasiones. En cambio, la resolución de problemas en equipo en un entorno de aprendizaje dinámico enfrentándose a problemas exigentes, y el desarrollo de las habilidades de análisis, de síntesis y de comunicación, tendrán un impacto mucho más positivo.\nHe intentado mostrar la necesidad de que los estudiantes comprendan y apliquen el método científico en el entorno industrial, y no sólo apliquen un recetario de procedimientos de manera automática. Son mucho mas importantes la comprensión y la utilización adecuada del método científico y de las herramientas y gráficos básicos, antes que la aplicación rutinaria y mecánica de determinadas fórmulas matemáticas o métodos sofisticados y complejos que el alumno puede no comprender en toda su profundidad.\nLas industrias líderes destacan por la aplicación intensiva de métodos tales como Six Sigma, Lean Manufacturing, diseño robusto de productos, y otros que hacen un uso intensivo de los datos, tanto de los obtenidos en producción como de los obtenidos en la realización de experimentos bien diseñados. Pero la mejora de la competitividad en estas empresas no se debe tanto a la aplicación de unos u otros métodos, como al desarrollo del juicio analítico de sus equipos humanos y a la aplicación de lo aprendido a la mejora continua de los procesos industriales. Veremos que la experiencia y el conocimiento tecnológico de estos procesos son fundamentales para el desarrollo del buen juicio analítico, y, en consecuencia, para la buena interpretación de los resultados que se obtienen con las herramientas estadísticas y de análisis.\nTratándose de un libro para el uso en la Formación Profesional, considero prioritario que su estudio se oriente al desarrollo de habilidades que sean de aplicación práctica directa en el puesto de trabajo y además faciliten la empleabilidad del estudiante, y no a la obtención de conocimiento abstracto. El Informe sobre el futuro del empleo, publicado por el Foro Económico Mundial en mayo de 2023 (World Economic Forum 2023), considera que las principales habilidades clave en el trabajo del futuro serán en primer lugar el desarrollo del pensamiento analítico y, en segundo, del pensamiento crítico; unidas al desarrollo de la curiosidad y la voluntad de aprendizaje a lo largo de la vida, la eficacia, la confianza en el propio trabajo y la atención al detalle. La voluntad de este libro es proporcionar conocimientos que ayuden al estudiante a desarrollarse en esta dirección.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#a-quién-va-dirigido-este-libro",
    "href": "index.html#a-quién-va-dirigido-este-libro",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "A quién va dirigido este libro",
    "text": "A quién va dirigido este libro\nEl libro está orientado a completar la formación técnica de los estudiantes de Formación Profesional, en las especialidades relacionadas con la actividad productiva industrial. También creo que será de utilidad para los técnicos industriales en activo que no han tenido la oportunidad de recibir una adecuada formación en estas metodologías, y que han encontrado dificultad para lanzarse a su aprendizaje mientras desarrollan so actividad profesional. Espero, también, que los profesores de la Formación Profesional en estos ámbitos de competencia encuentren en este documento los elementos de apoyo que les permitan integrar estas enseñanzas en sus respectivos ciclos formativos.\nEn todos los casos, el aprendizaje requerirá de un esfuerzo que quizás será mayor en los estudiantes que no tengan una base mínima en álgebra y cálculo. En estos casos, el trabajo en equipo y la discusión abierta entre compañeros y con los profesores ayudará a la comprensión de los conceptos.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#organización-del-libro",
    "href": "index.html#organización-del-libro",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "Organización del libro",
    "text": "Organización del libro\nEl capítulo 1 hace una introducción general al pensamiento estadístico y su aplicación industrial, y presenta algunos conceptos básicos, tales como población, muestra y variable.\nEl capítulo 2 presenta las dos herramientas básicas que se usarán en el libro, la hoja de cálculo y el programa estadístico de código abierto R. Se describen los aspectos básicos del software estadístico R y sus principales aplicaciones en la manipulación, limpieza y análisis de conjuntos de datos. Se introduce también el concepto actual de reproducibilidad, y se explica su importancia y el impacto de utilizar una hoja de cálculo o un análisis basado en un script programado.\nEn el capítulo 3 se hace una introducción al concepto de flujo de trabajo y al concepto de datos ordenados o tidy data, que resulta fundamental para las fases posteriores de análisis. Se explica también cómo mover datos desde excel a R y viceversa.\nEl capítulo 4 habla de la exploración de los datos como primer paso en el análisis. Presenta los principales tipos de gráficos que se utilizan en esta fase del análisis, y explica cómo utilizar Excel y R en esta fase del análisis.\nEn el capítulo 5 se presentan los principales estadísticos que describen una población, mediante un valor central y una medida de dispersión, tanto paramétricos (media y varianza) como no paramétricos (mediana y rango intercuartil), de forma sencilla y sin recurrir a explicaciones matemáticas o estadísticas avanzadas.\nEl capítulo 6 introduce las distribuciones de frecuencia, y a continuación el concepto de probabilidad, así como las distribuciones de probabilidad, necesarias para la construcción de los tests de hipótesis y, en general, de la estadística inferencial. Este contenido se presenta de forma breve y, sobre todo, práctica.\nEn el capítulo 7 se presentan los métodos para detectar la relación entre dos variables (correlación y regresión lineal), haciendo énfasis en los métodos gráficos, y se discuten las diferencias entre correlación y causalidad.\nEl capítulo 8 introduce de manera sencilla el análisis de la varianza, necesario para métodos importantes en la industria como el control de la precisión analítica, que se trata en el capítulo siguiente.\nEl capítulo 9 trata del análisis del sistema de medición, la calidad de las medidas y la medida de la precisión analítica. Resulta sorprendente la cantidad de laboratorios que dan soporte analítico a procesos productivos de gran impacto económico en la vida de la empresa, sin realizar nunca un autocontrol sobre el nivel de precisión de sus análisis. En este capítulo se hace una presentación básica del tema con el objetivo de que resulte útil y práctica.\nEl capítulo 10 presenta una de las aplicaciones más importantes de la estadística en el entorno industrial, el control estadístico de procesos. Dada la importancia de este capítulo, se refuerza su contenido con numerosos ejemplos y casos prácticos, y se incluye un caso extenso para su análisis.\nEn el capítulo 11 se hace una introducción al diseño de experimentos. La utilidad de esta técnica es primordial para el industrial, sobre todo para el área de I+D y el diseño de productos. Dado que esta técnica puede ser muy compleja en su aplicación real, se facilitan enlaces a otros recursos, como cursos, que serán útiles a los que quieran profundizar más.\nEn el capítulo 12 se presenta el uso de los conceptos y técnicas estudiadas en los procesos de mejora de la calidad industrial, y se introducen algunas aplicaciones prácticas de la estadística en el entorno industrial, como Six Sigma.\nEl capítulo 13 hace una breve introducción a las técnicas de comunicación, tanto a la presentación de datos como a la preparación de informes. Se hace hincapié en las nuevas herramientas como Quarto, que facilitan la elaboración de informes automatizados.\nFinalmente, se hace una introducción a R en anexo.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#cómo-usar-el-libro",
    "href": "index.html#cómo-usar-el-libro",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "Cómo usar el libro",
    "text": "Cómo usar el libro\nHe intentado que cada capítulo sea lo más autocontenido posible de forma que se facilite la organización pedagógica por temas. No obstante, a veces puede ser necesario conocer los contenidos de los capítulos anteriores, por lo que se sugiere estudiarlo en el orden presentado.\nEl libro es eminentemente práctico, con numerosos ejercicios; su resolución puede ser individual o en equipo.\nAlgunos recuadros utilizan códigos de color para indicar el objetivo de la información que contienen. Básicamente, los colores utilizados son:\n\n\n\n\n\n\nProblema o cuestión a resolver\n\n\n\nEl recuadro azul se utilizará para proponer problemas sencillos cuya respuesta se encuentra más adelante en el texto. El objetivo de estos problemas es estimular la reflexión, aunque puede ser necesario recurrir a cálculos sencillos ayudados por las herramientas disponibles.\n\n\n\n\n\n\n\n\nRespuesta al problema o cuestión a resolver\n\n\n\n\n\nEl recuadro verde se utilizará para proponer una respuesta al problema planteado; respuesta que no tiene por qué ser la única posible. Normalmente se presentará de forma oculta.\n\n\n\nAdemás se incluyen diferentes tipos de avisos cada vez que se introduce algún concepto que es necesario resaltar.\n\n\n\n\n\n\nImportante\n\n\n\nEn este formato se indican cuestiones importantes\n\n\n\n\n\n\n\n\n¡Atención!\n\n\n\nEn este formato se indican cuestiones a las que hay que prestar especial atención o que pueden inducir a error",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#uso-del-ordenador-y-el-software-estadístico",
    "href": "index.html#uso-del-ordenador-y-el-software-estadístico",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "Uso del ordenador y el software estadístico",
    "text": "Uso del ordenador y el software estadístico\nEn la práctica diaria, los técnicos industriales usan los ordenadores para almacenar y visualizar los datos de producción, para solucionar problemas mediante análisis estadísticos, y para presentar sus resultados de forma gráfica. De la misma forma que en el entorno industrial, en este libro se utilizarán también los ordenadores de forma habitual, y por esta razón es imprescindible que los estudiantes tengan acceso individual a un ordenador en el que esté instalado el software recomendado, y que se acostumbren a utilizarlo para resolver los problemas y casos planteados como ejercicios prácticos, individualmente y en grupo.\nEl estudiante que se incorpora a una empresa, sea en un laboratorio o en una planta de producción, se va a encontrar muy pronto delante de una hoja de cálculo, y debe saber cómo utilizarla correctamente. Actualmente, lo más probable es que esa hoja de cálculo sea Microsoft Excel, aunque hay otras alternativas posibles, como Google Sheets, Apple Numbers, OpenOffice Calc y algunas más. La gran dominancia en el mercado de Microsoft Excel ha hecho que todas estas herramientas sean totalmente compatibles o tengan modos de compatibilidad con Excel. Por esta razón, este libro se basa en la utilización de Excel como hoja de cálculo y herramienta principal para el almacenamiento de datos.\nA lo largo del libro se presentarán informes y gráficos obtenidos con Microsoft Excel, y también con el software estadístico R. Prácticamente todos ellos pueden ser exportados a otras herramientas, como Google Sheets, OpenOffice, Minitab o Matlab, o analizarse con otros lenguajes de programación, como Python o Julia. En realidad, el método de análisis y cómo obtener un resultado correcto son aspectos más importantes que la herramienta que se utilice para ello, por lo que queda en manos del instructor la decisión final sobre qué usar y cómo. Para facilitar este trabajo de conversión, en su caso, todo el material del libro y los datos de ejemplo estarán disponibles en un repositorio de GitHub.\nAlgunos ejercicios tienen que ver con la interpretación y presentación de los resultados. Es importante que estos trabajos se realicen en grupo y se haga énfasis en la comprensión del problema y en su correcta exposición; en los equipos industriales de hoy, la discusión de problemas y la exposición de resultados, en reuniones de trabajo o en paneles informativos a pie de planta, forma parte del trabajo diario. Estas habilidades de comunicación deben ser desarrolladas en los estudiantes de forma prioritaria.\nLa ventaja de R sobre Excel es que el código R, si está bien documentado, muestra cada paso realizado, y esto permite que otras personas puedan verificar el resultado y reproducirlo a partir de los datos originales, e incluso reutilizar los procedimientos. Utilizar código en vez de clicks de ratón es esencial para asegurar la reproducibilidad de los análisis de datos1. Por esta razón, recomiendo el uso del lenguaje R como complemento o alternativa a la hoja de cálculo, tanto para analizar como para visualizar datos. Sin embargo, como la realidad del mundo de la empresa es que los lenguajes como R están todavía poco introducidos, es inevitable mantener el uso de la hoja de cálculo; en el libro se explicarán algunas mejores prácticas, que permitirán el uso simultáneo de ambas herramientas de forma óptima.\nRespecto a la programación informática, en el libro no se hace énfasis en la programación R más que como sucesión de órdenes individuales en scripts sencillos. No se busca la eficiencia computacional ni la rapidez en el cálculo, sino la comprensión de la metodología de resolución de problemas y cómo ésta se apoya en las herramientas presentadas. De la misma manera, tampoco se hace ningún uso de la programación en Excel, ya sea con macros o con Visual Basic; estos temas quedan fuera del perímetro de este libro.\nUn paso en la dirección de la implantación de flujos de trabajo reproducibles es la elaboración de informes automatizados. Estos informes incluyen el código R, los comentarios del autor en forma de texto formateado en markdown, y los resultados del código. Herramientas como Quarto, o Google Colaboratory, que usa la interface Jupyter, son nuevas formas de elaborar y presentar los informes y resultados estadísticos. En el entorno docente, estas herramientas abren posibilidades muy interesantes en la presentación de un ejercicio o un exámen escrito, ya que el alumno puede detallar perfectamente todos los pasos hasta llegar al resultado final, y facilita la revisión por sus compañeros o por el profesor a cargo de la asignatura.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#sec-aprendizaje",
    "href": "index.html#sec-aprendizaje",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "Recursos adicionales y cómo usarlos",
    "text": "Recursos adicionales y cómo usarlos\nEn este libro se hace una introducción muy general a R y a Excel; se presupone que el alumno tiene un conocimiento básico de ambas herramientas. Si no tiene ninguna formación sobre el lenguaje R y el entorno RStudio, recomiendo hacer alguna formación previa sencilla que introduzca los conceptos básicos. Datacamp tiene cursos gratuitos de introducción a R; también hay cursos de formación tanto de R como de Excel en otras plataformas web como edX, Udemy y Coursera, muchos de ellos gratuitos. El Gobierno de España, dentro de una de sus iniciativas de transformación digital, la iniciativa de datos abiertos, incluye también una amplia referencia a cursos de formación sobre R.\nTodos los datos presentados en los ejemplos se incluyen en hojas de cálculo que están disponibles en GitHub. También se incluyen fuentes de datos adicionales que pueden permitir plantear nuevos ejercicios.\nAl final del libro se incluye una bibliografía completa.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#sobre-el-libro",
    "href": "index.html#sobre-el-libro",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "Sobre el libro",
    "text": "Sobre el libro\nEl libro ha sido editado en Quarto. Está disponible en PDF.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "Agradecimientos",
    "text": "Agradecimientos\n\n\n\n\n\nWorld Economic Forum. 2023. «Future of Jobs Report, 2023». 91-93 route de la Capite,CH-1223 Cologny/Geneva, Switzerland: World Economic Forum. https://www.weforum.org/publications/the-future-of-jobs-report-2023/.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Introducción a la estadística industrial y la ciencia de datos utilizando Microsoft Excel y R",
    "section": "",
    "text": "El concepto de reproducibilidad, cada vez más importante, se desarrolla en el capítulo 1↩︎",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "010-intro.html",
    "href": "010-intro.html",
    "title": "1  La estadística en el entorno industrial.",
    "section": "",
    "text": "1.1 Introducción\nLa estadística es la ciencia de aprender a partir de los datos. Implica la recolección, análisis y presentación de los datos, y su utilización para tomar decisiones y resolver problemas.\nHay muchos aspectos del trabajo industrial que implican recoger datos, trabajar con ellos y utilizarlos para resolver un problema; el uso de la estadística es sólo una herramienta más, tan importante como cualquier otra disciplina en el bagaje de conocimientos de un científico, ingeniero o técnico industrial.\nLos métodos estadísticos nos ayudan a describir y comprender la variabilidad. Cuando hablamos de variabilidad queremos decir que sucesivas observaciones de un mismo proceso o sistema no dan exactamente los mismos resultados. Por ejemplo, el consumo de gasolina de un coche no es siempre igual, sino que varía de manera considerable. Esta variación depende de muchos factores, como la forma de conducir, el tipo de carretera, la situación del propio vehículo (presión de neumáticos, compresión del motor, …), la marca de la gasolina, el octanaje, o incluso las condiciones meteorológicas. Todos estos factores son causas de variabilidad en el consumo de gasolina. La estadística nos permite analizar estos factores y determinar cuáles son los más importantes o tienen mayor impacto en el consumo; una vez conocidos, podemos actuar sobre ellos.\nEn este libro aprenderemos a utilizar herramientas diversas, tanto estadísticas como de la ciencia de datos, para realizar nuestro análisis. Para aprender de los datos necesitamos más que los simples números; para interpretarlos necesitaremos siempre el conocimiento del proceso industrial que estamos analizando.En un análisis de la producción de un producto lácteo, por ejemplo, los números significan poco sin un conocimiento del proceso; los valores de pH, temperatura o concentración de lactosa influyen en el resultado del proceso de forma diferente. Los datos son números dentro de un contexto, y necesitamos conocer este contexto para dar sentido a los números.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La estadística en el entorno industrial.</span>"
    ]
  },
  {
    "objectID": "010-intro.html#introducción",
    "href": "010-intro.html#introducción",
    "title": "1  La estadística en el entorno industrial.",
    "section": "",
    "text": "Importante\n\n\n\nEl objetivo principal de la mejora industrial es la reducción de la variabilidad.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La estadística en el entorno industrial.</span>"
    ]
  },
  {
    "objectID": "010-intro.html#método-científico-y-pensamiento-estadístico.",
    "href": "010-intro.html#método-científico-y-pensamiento-estadístico.",
    "title": "1  La estadística en el entorno industrial.",
    "section": "1.2 Método científico y pensamiento estadístico.",
    "text": "1.2 Método científico y pensamiento estadístico.\nLos ingenieros y técnicos resuelven problemas de interés para la empresa y la sociedad mediante la aplicación de los principios del método científico, siguiendo estos pasos:\n\nPreparar una descripción clara y concisa del problema\nIdentificar, al menos de forma tentativa, los principales factores que afectan al problema, o que podrían tener un papel en su resolución\nProponer un modelo para el problema, usando conocimiento científico o tecnológico del proceso en estudio, dejando constancia de las limitaciones del modelo propuesto.\nRealizar experimentos apropiados y recolectar datos para probar o validar el modelo tentativo o las conclusiones previas obtenidas en los pasos 2 y 3\nRefinar el modelo sobre la base de los datos observados\nManipular el modelo para desarrollar una solución al problema\nRealizar un experimento adecuado para confirmar que la solución propuesta es efectiva y eficiente.\nSacar las conclusiones oportunas o hacer recomendaciones basándose en la solución encontrada.\n\n\n\n\n\n\nflowchart LR\n  A[Describir el problema &lt;br&gt; con claridad] --&gt; B[Identificar &lt;br&gt; los factores &lt;br&gt; más importantes]\n  B --&gt; C[Proponer &lt;br&gt; o refinar &lt;br&gt; un modelo]\n  C --&gt; D[Recoger &lt;br&gt; datos]\n  D --&gt; B\n  C --&gt; E[Manipular &lt;br&gt; el modelo]\n  E --&gt; F[Confirmar &lt;br&gt; la solución]\n  F --&gt; G[Sacar conclusiones &lt;br&gt; y hacer las recomendaciones]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La estadística en el entorno industrial.</span>"
    ]
  },
  {
    "objectID": "010-intro.html#los-datos-industriales",
    "href": "010-intro.html#los-datos-industriales",
    "title": "1  La estadística en el entorno industrial.",
    "section": "1.3 Los datos industriales",
    "text": "1.3 Los datos industriales\n\n1.3.1 El origen de los datos\nEn el entorno industrial (Douglas C Montgomery 2011), los datos provienen casi siempre de una de estas tres vías:\n\nEstudio retrospectivo, basado en datos históricos\nEstudio observacional\nExperimento diseñado\n\nUn buen sistema de recogida de datos facilitará el estudio posterior. Si ponemos poco cuidado en la toma de datos y en la forma de guardarlos, nos encontraremos después con dificultades en la fase de análisis o en la de interpretación; en algunos casos, estas dificultades se convertirán en problemas imposibles de resolver.\n\n\n1.3.2 Estudios retrospectivos o históricos\nUn estudio retrospectivo o histórico es el que utiliza una muestra o todos los datos históricos de un proceso, recogidos en el pasado durante un período determinado de tiempo. El objetivo de un estudio de este tipo puede ser la investigación sobre la relación entre algunas variables, o explorar la calidad de la información disponible, o construir un modelo que permita explicar el proceso tal como es actualmente, o saber si se ha desviado. Estos modelos del proceso se denominan modelos empíricos, porque están basados en los propios datos del proceso y no en una formulación teórica sobre el mismo.\nUn estudio retrospectivo tiene la ventaja de tener a su disposición un gran número de datos que ya han sido recogidos, minimizando el esfuerzo de obtenerlos. Sin embargo, tiene varios problemas potenciales:\n\nSi no disponemos de detalles suficientes, es posible que no podamos determinar si las condiciones de variación de los valores obtenidos responden a las mismas causas que en la situación actual.\nEs posible que nos falte algún valor clave que no haya sido recogido o que lo haya sido de manera defectuosa\nAlgunas veces, la fiabilidad y validez de los datos de proceso históricos son dudosas, o al menos, cuestionables.\nLos datos históricos no siempre se han recogido con la perspectiva actual del proceso, y es posible que no nos proporciones explicaciones adecuadas del proceso en su situación actual.\nA veces queremos utilizar los datos históricos de proceso para fines que no estaban previstos cuando se recogieron\nLas notas sobre los valores del proceso, incluyendo los valores anormales, pueden ser insuficientes o inexistentes, y no tenemos ninguna explicación sobre los posibles valores anómalos que detectamos en el análisis.\n\nUsar datos históricos siempre tiene el riesgo de que, por la razón que sea, no se hayan recogido datos importantes, o que estos datos se hayan perdido, o se hayan transcrito de forma inadecuada o incorrecta. Es decir, los datos históricos pueden tener problemas de calidad de datos.\nEl hecho de que algunos datos se hayan recogido históricamente no siempre quiere decir que estos datos sean relevantes o útiles. Cuando el grado de conocimiento del proceso no es suficiente, o no se basa en un análisis metódico y riguroso de los datos, es posible que no se hayan recogido algunos datos que pueden ser importantes para el proceso, a veces simplemente porque son complejos o difíciles de analizar. Los datos históricos no pueden proporcionar la información que buscamos si la información de las variables clave nunca se ha recogido o se ha hecho sin una buena base experimental.\nEl propósito del análisis de los datos industriales es aislar las causas que están detrás de los sucesos que afectan e influyen en los procesos. En los datos históricos, estos sucesos pueden haber ocurrido semanas, meses o incluso años antes, sin que haya registros ni notas que hayan intentado explicar estas causas, y los recuerdos de las personas que han participado en ellos se pierden con el tiempo, o se alteran involuntariamente, proporcionando explicaciones supuestamente válidas pero que en realidad son incorrectas. Por eso, con frecuencia, el análisis de los datos históricos puede poner de manifiesto hechos interesantes, pero sus causas quedan sin explicar.\nLos estudios históricos pueden requerir una fase previa de preparación y depuración de datos que puede llegar a ser muy larga y tediosa. Se estima que en muchos estudios de ciencia de datos, el tiempo de preparación de los datos puede llegar al \\(60\\%\\) del tiempo total empleado en el estudio. Las herramientas de análisis de datos son de gran ayuda en esta fase del proceso, aunque en muchas ocasiones será necesario un trabajo manual de recolección de datos en papel, hojas de cálculo diversas y otras fuentes. Esta fase es muy útil no sólo para la preparación de datos para el estudio, sino para mejorar el conocimiento de los datos, cómo se originan y cómo se almacenan. Este conocimiento siempre es de gran utilidad para mejorar los procedimientos actuales de captura de datos, facilitando la fiabilidad de los análisis futuros.\n\n\n1.3.3 Estudios observacionales\nComo su nombre indica, un estudio observacional simplemente observa un proceso durante un tiempo de operación en rutina. Normalmente, el ingeniero o técnico interfiere lo mínimo posible en el proceso; sólo lo suficiente para recoger la información que necesita, si piensa que esa información puede ser relevante. En muchas ocasiones, el estudio no forma parte de los controles de rutina, y representa un trabajo adicional.\nSi se planifican adecuadamente, los estudios observacionales proporcionan datos fiables, precisos y completos para documentar un proceso. Por otra parte, estos estudios proporcionan una información limitada sobre las relaciones entre las variables del proceso, porque es posible que durante el tiempo limitado de observación, el rango de variación de las variables no recoja todas las situaciones posibles; por ejemplo, las situaciones extraordinarias.\n\n\n1.3.4 Experimentos diseñados\nLa tercera forma de recoger información de un proceso son los experimentos diseñados. En un experimento de este tipo, el ingeniero o técnico hace un cambio deliberado en las variables que controla (llamadas factores), observa el resultado, y toma una decisión respecto a qué variable o variables son responsables de los cambios que observa en el proceso.\nUna diferencia importante respecto a los estudios históricos y los observacionales es que las diferentes combinaciones de factores se aplican al azar sobre un conjunto de unidades experimentales. Esto permite establecer con precisión las relaciones causa-efecto, cosa que no suele ser posible ni en los estudios históricos ni en los observacionales.\n\n\n\n\n\n\nExperimentos diseñados\n\n\n\nEn el capítulo 11 se hará una introducción básica al diseño de experimentos",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La estadística en el entorno industrial.</span>"
    ]
  },
  {
    "objectID": "010-intro.html#algunas-definiciones-importantes",
    "href": "010-intro.html#algunas-definiciones-importantes",
    "title": "1  La estadística en el entorno industrial.",
    "section": "1.4 Algunas definiciones importantes",
    "text": "1.4 Algunas definiciones importantes\n\n1.4.1 Población y muestra\nUna población es un conjunto de de personas, cosas o, en general, objetos en estudio. A veces, una población es demasiado grande para que podamos abarcarla completa; para poder estudiarla, obtenemos una muestra, que consiste en un subconjunto de la población que hemos seleccionado para su estudio. El proceso de obtener una muestra se llama muestreo, y se realiza de acuerdo con normas y procedimientos específicos.\nEn muchas ocasiones, cuando se recogen los datos como resultado de una experimentación, definimos la población como todos los resultados que podríamos haber obtenido. Llamamos a este conjunto de posibles resultados una población conceptual. Por ejemplo, cuando medimos el \\(pH\\) de varias muestras de leche, la población es el conjunto de todos los resultados posibles que podríamos haber tenido. Muchos problemas de ingeniería y tecnología se refieren a poblaciones conceptuales.\n\n\n\n\n\n\nRecuerda\n\n\n\nEn la mayoría de las ocasiones, nuestros datos provienen de una muestra obtenida de una población,\n\n\nCuando tomamos una muestra, debemos estar seguros de que contiene las propiedades que queremos estudiar en la población. En ese caso, decimos que la muestra es representativa: los individuos de la muestra son representativos de la población. Para que la muestra sea representativa, debe ser obtenida mediante un muestreo aleatorio. Una muestra aleatoria simple de tamaño \\(n\\) consiste en \\(n\\) individuos de una población, elegidos de forma que cada conjunto posible de \\(n\\) individuos tiene la misma probabilidad de ser elegido.\n\n\n\n\n\n\n¿Qué es la probabilidad?\n\n\n\nEl concepto de probabilidad se explica en el capítulo 6\n\n\n\n\n1.4.2 Parámetro y estadístico\nUn parámetro es una característica de una población. Podemos estimar su valor mediante la extracción de una muestra, que utilizaremos para calcular un estadístico muestral. Llamamos estadístico a un número que representa una propiedad o característica de la muestra, y constituye una estimación del valor de un parámetro de la población que estamos estudiando.\n\n\n1.4.3 Variables y casos\nA los objetos descritos en un conjunto de datos los llamamos casos, de forma genérica. A veces, estos casos pueden corresponder a personas; en ese caso podemos llamarlos individuos. Cuando los objetos que estudiamos no son personas, como es lo habitual en el entorno industrial, utilizamos la nomenclatura genérica.\nUn atributo es una característica que define una propiedad de un objeto, persona o cosa. Por ejemplo, edad, peso, altura, sexo, color de ojos, son atributos de una persona. Llamamos variable a una característica cualquiera de un individuo que puede ser medida. Una variable puede tomar diferentes valores en diferentes individuos o casos.\nSegún estas definiciones que acabamos de ver, una muestra está formada por un conjunto de casos, y cada caso contiene un determinado número de variables, que contienen los valores que hemos analizado o medido.\n\n\n\n\n\n\nEjemplo 1: Muestreando una cámara de maduración de queso\n\n\n\nImagínate que tienes que analizar el extracto seco de una producción de queso que está en fase de maduración en una cámara. Como la cámara está muy llena, es difícil acceder al interior, y decides coger tu muestra de los quesos que están más a tu alcance, justo al lado de la puerta y a la altura de la vista.¿Crees que es una buena idea? ¿Podrías definir la población en este caso?.\n\n\n\n\n\n\n\n\nRespuesta al ejemplo 1: Muestreando una cámara de maduración de queso\n\n\n\n\n\nNo es una buena idea porque no tenemos garantía de que las condiciones de humedad,temperatura y circulación de aire sean las mismas en toda la cámara. Para asegurar que nuestra muestra es representativa, debemos tomar una muestra aleatoria de la población, que en este caso es el total de quesos en la cámara.\n\n\n\n\n\n1.4.4 Tipos de variables\nAlgunas variables, como el color, sirven para clasificar los individuos en categorías. Otras, como la altura o el peso de un individuo, pueden tomar valores numéricos con los que podemos hacer cálculos. Por ejemplo, podemos sumar la altura de varias personas, pero no tiene sentido sumar los colores del arco-iris (aunque sí podemos contarlos, y hacer cálculos con estos recuentos). También podemos categorizar variables continuas: podemos clasificar nuestro grupo de personas en altas o bajas, y podemos contar cuántas personas entran en cada categoría.\n\n\n\n\n\n\n\n\n\nVariables cualitativas  o categóricas\n\nVariables cuantitativas  o métricas\n\n\n\n\n\nNominales\nOrdinales\nDiscretas\nContinuas\n\n\nValores en categorías arbitrarias\nValores en categorías ordenadas\nValores enteros en escala numérica\nValores continuos en escala numérica\n\n\n(sin unidades)\n(sin unidades)\nUnidades contadas\nUnidades medidas\n\n\n\nUna variable categórica coloca a un individuo en uno o más grupos o categorías\nUna variable métrica toma valores numéricos con los que tiene sentido realizar cálculos aritméticos como sumar, restar, etc.\nLas variables categóricas se conocen también como variables cualitativas porque indican cualidades.\nLas variables métricas se conocen también como variables cuantitativas porque indican cantidades.\n\n\n\n\n\n\nComentario: ¿Cualitativo quiere decir “que tiene calidad”?\n\n\n\nA veces se utiliza la palabra cualitativo de forma incorrecta para indicar calidad, por ejemplo cuando alguien dice: “Este envase es muy cualitativo”. Deberíamos decir “Este envase tiene gran calidad”. Cualitativo no se deriva de calidad, sino de cualidad.\n\n\n\n\n\n\n\n\nPara resolver\n\n\n\nEjemplo 1. Tiramos un dado al aire. Describe a qué corresponde la variable y el caso.\nEjemplo 2. Durante un proceso de envasado de un producto que dura una hora, controlamos el peso de cada envase cada minuto. Describe la variable y el caso. ¿Puede haber más de una variable?\n\n\n\n\n\n\n\n\nRespuestas: Para resolver\n\n\n\n\n\nEjemplo 1: La variable es el resultado que obtenemos cada vez; podríamos denominarla, por ejemplo, \\(resultado\\_obtenido\\). Colocaríamos este nombre en el encabezado de una columna en una hoja de cálculo. Cada tirada que hacemos es un caso; iríamos colocando el resultado que obtenemos cada vez en una nueva fila de nuestra hoja de cálculo.\nEjemplo 2. En este caso, la variable es el \\(peso\\_obtenido\\), y cada pesada constituye un caso. Si registrásemos, además, la hora y el minuto en el que que hemos hecho cada control de peso, podríamos definir una nueva variable, que podríamos llamar \\(hora\\), y que colocaríamos en una columna al lado del \\(peso\\_obtenido\\). Incluso podríamos definir otra variable adicional, el \\(numero\\_de\\_pesada\\), que sería un número secuencial empezando en \\(1\\) y que se incrementaría en cada pesada, de forma que al final esta variable nos daría el número de pesadas realizadas, y nos indicaría además el orden en el que las hemos realizado. Puesto que hemos realizado una pesada cada minuto, tendríamos tres variables y 61 líneas (un encabezado y 60 líneas correspondientes una a cada minuto)\n\n\n\n\n\n1.4.5 Reglas básicas para establecer los nombres de las variables.\nSegún hemos visto, existen diferentes tipos de variables, cualitativas (categóricas) y cuantitativas (métricas). Normalmente, los valores de las variables categóricas se describen mediante textos del tipo “color blanco”, “hombre”, “mujer”, “alto”, “bajo”, etc.  Suelen corresponder con características descriptivas, y por lo tanto, no puede hacerse cálculos directamente con ellos, a menos que se hayan resumido, por ejemplo, mediante un conteo. Las variables métricas consisten en valores numéricos, que pueden ser enteros o continuos, y pueden utilizarse directamente para hacer cálculos tales como sumas, etc.A partir de aquí utilizaremos una nomenclatura compatible con las hojas de cálculo en formato europeo para escribir los números; usaremos la coma para la separación decimal y el punto y coma para la separación de los números cuando los escribamos de forma seriada.\nUna variable está descrita siempre por un nombre, que designa la variable, y un valor o conjunto de valores, que corresponden a los casos. Este conjunto de valores, como acabamos de ver, pueden ser textos o números.\nExisten también otros tipos de variables que veremos más tarde, como variables lógicas o fechas, según el tipo de dato que almacenemos en esa variable.\nEjemplos de valores de texto: “Carlos”, “fruta”, “Lluvia fuerte”, “muy ácido”, “sabor a fresa”\nEjemplos de valores numéricos: \\(1\\); \\(7\\); \\(10,65\\)\nSiempre que sea posible, utilizaremos el nombre del atributo o característica que estamos midiendo o analizando, o su abreviatura, para designar una variable; por ejemplo, si estamos recogiendo la altura de una serie de personas, llamaremos altura a la variable; si estamos recogiendo el peso, usaremos el nombre peso, etc.\nA veces, asignar un nombre a una variable no es todo lo fácil que podría parecer a simple vista. Por ejemplo, ¿qué nombre daríamos a una variable que va a recoger los valores de \\(pH\\) de la leche en una cuba de queso en el momento de añadir el cuajo? Está claro que \\(pH\\) no es suficiente, porque en el proceso hay varias medidas de \\(pH\\) y sería bueno que pudiésemos diferenciarlas con facilidad. En un caso como éste, es probable que necesitemos utilizar varias palabras o abreviaturas que describan mejor el nombre de la variable.\nPara la construcción correcta de estos nombres, se han establecido un conjunto de reglas, con el objetivo de evitar errores y facilitar el intercambio de los datos entre diferentes programas de análisis. Son éstas:\n\nUn nombre válido consiste en una combinación de letras, números y signo de subrayado (\\(\\_\\))\nUn nombre de variable no puede empezar por un número, un punto o un signo de subrayado (\\(\\_\\)); debe empezar siempre por una letra.\nLos nombres de variables irán siempre en minúsculas. Según esta regla, \\(Peso\\) no es un nombre válido, pero \\(peso\\) si lo es.\nNo utilizaremos espacios en blanco, acentos ni caracteres especiales como \\(\\tilde{n}\\), \\(\\%\\), guiones o paréntesis.\nHay veces en que nos interesa unir varias palabras para construir un nombre de variable. Se utilizan diferentes formas de unir palabras, por ejemplo:\n\nun punto, como en \\(peso.en.cm\\),\nlo que se ha llamado escritura de camello (camelCase), que se llama así por el uso de mayúsculas y minúsculas mezcladas (\\(PesoEnCm\\))\nel signo de subrayado \\(\\_\\), como en \\(peso\\_en\\_cm\\)\n\nAlgunas de estas opciones son utilizadas en distintas comunidades de usuarios, por ejemplo la opción 1 es utilizada en la guía de estilo de Google, y la opción 2 es muy utilizada por los programadores del entorno de los lenguajes de Microsoft. Nosotros utilizaremos el signo de subrayado (\\(\\_\\)), que es la forma más usada en el entorno de programación de R.\nSiempre se separarán las palabras mediante el signo de subrayado (_) para facilitar la lectura. Así, aunque \\(temperatura1\\) es un nombre válido, preferiremos \\(temp\\_1\\); es más corto y de lectura más clara. Igualmente, preferiremos \\(peso\\_empaquetado\\) a \\(pesoempaquetado\\)\nMantendremos los nombres razonablemente cortos para facilitar la lectura. Aunque podemos hacer los nombres todo lo largos que queramos, es más cómodo utilizar nombres cortos. Por ejemplo, podríamos utilizar \\(temperatura\\_de\\_la\\_leche\\_al\\_cuajar\\), pero preferiremos abreviarlo como \\(temp\\_cuajo\\).\n\nNombres no válidos:\n\n\\(peso\\ en\\ gramos\\) (contiene espacios)\n\\(pH\\_de\\_la\\_leche\\_en\\_Recepci\\acute{o}n\\) (demasiado largo, tiene un acento, tiene mayúsculas)\n\\(extracto\\_seco\\_total\\_a\\_la\\_salida\\_de\\_la\\_salmuera\\) (demasiado largo)\n\nAlternativas válidas:\n\n\\(peso\\_g\\)\n\\(pH\\_leche\\_rec\\) (en este caso, de manera excepcional, podemos mantener el uso de la mayúscula por corrección formal)\n\\(est\\_salida\\_sal\\)\n\nUn caso particular es el uso de la \\(\\tilde{n}\\), ya que no hay una alternativa fácil para el uso en las fechas (\\(a\\tilde{n}o\\)). R admite el uso de la \\(\\tilde{n}\\) en los nombres de variables, por lo que podremos usarlo con cuidado, poniendo atención a los posibles errores que se pudiesen producir en algunas librerías.\n\n\n\n\nDouglas C Montgomery, Norma Faris Hubele, George C Runger. 2011. Engineering Statistics. 111 River Street, Hoboken, NJ 07030-5774: John Wiley & Sons, Inc.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La estadística en el entorno industrial.</span>"
    ]
  },
  {
    "objectID": "020-herramientas.html",
    "href": "020-herramientas.html",
    "title": "2  Herramientas para el análisis. La reproducibilidad.",
    "section": "",
    "text": "2.1 Introducción\nEn este capítulo veremos las herramientas que utiizaremos en el análisis de datos industriales. Nos enfocaremos en dos de ellas: la hoja de cálculo Microsoft Excel, y el software estadístico R. Ambas herramientas están ampliamente extendidas en las empresas y en las instituciones docentes de todo el mundo. R es, además, un software libre, y por lo tanto, con un coste de adquisición cero, lo que facilita su utilización. Microsoft Excel tiene versiones web que se pueden utilizar para un uso básico también sin coste. No son las únicas opciones: hay otros programas estadísticos y de análisis muy utilizados y potentes, tales como Matlab o Minitab, que son de gran interés en ingeniería, aunque tienen un coste bastante elevado, y hojas de cálculo como Google Docs o LibreOffice, casi totalmente compatibles con Microsoft Excel.\nEste capítulo no es un manual de aprendizaje de estas herramientas; se supone que se dispone del conocimiento básico para comprender las instrucciones que se proporcionarán aqui. Como se indicó en el prefacio (ver Sección 5), en internet hay multitud de alternativas de calidad para aprender tanto Excel como R de forma gratuita, en ese capítulo se presentaron algunas recomendaciones.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Herramientas para el análisis. La reproducibilidad.</span>"
    ]
  },
  {
    "objectID": "020-herramientas.html#la-hoja-de-cálculo",
    "href": "020-herramientas.html#la-hoja-de-cálculo",
    "title": "2  Herramientas para el análisis. La reproducibilidad.",
    "section": "2.2 La hoja de cálculo",
    "text": "2.2 La hoja de cálculo\nLa hoja de cálculo es una herramienta presente hoy día en todos los ámbitos de trabajo y educativos. Desde la aparición de Visicalc, en 1978, ha contribuido a la gestión de miles de empresas, se ha utilizado de manera general en análisis de datos y sus gráficos se han utilizado y se utilizan en publicaciones e informes de todas clases. En la década de los años 80 del pasado siglo, la hoja de cálculo Lotus 1-2-3 fue la aplicación más utilizada en los ordenadores IBM-PC y compatibles, y consiguió facturaciones millonarias para la empresa matriz. Lotus 1-2-3 dominó el mercado hasta la aparición de Microsoft Windows a finales de los años 80; este nuevo sistema operativo favoreció la implantación de Microsoft Excel, que desde entonces se convirtió en la hoja de cálculo dominante.\n\n\n\n\n\n\n\n\n\nVisicalc, primera hoja de cálculo para el ordenador Apple II (1979)\n\n\n\n\n\n\n\nHoja de cálculo Lotus 1-2-3 para MS-DOS (1983)\n\n\n\n\n\n\n\n\n\nMicrosoft Excel (2023)\n\n\n\n\n\n\n2.2.1 Aplicaciones de la hoja de cálculo\nLas hojas de cálculo son muy útiles para recoger la información de un conjunto de observaciones. Entre sus principales usos, están:\n\nLa introducción, edición y almacenamiento datos.\nEl filtrado y corrección de errores.\nLa manipulación básica, por ejemplo, mediante tablas dinámicas\nLa preparación y edición de gráficos, incluyendo gráficos dinámicos\nLa presentación de la información, con el apoyo opcional de herramientas adicionales como Microsoft PowerPoint.\n\nLos datos se pueden recoger y guardar de múltiples formas. Cuando la recogida de datos se hace de forma manual en papel, es necesario registrar en el ordenador los datos recogidos. Lo más frecuente es que este registro se haga en hojas de cálculo, como Microsoft Excel o Google Sheets. En algunos casos, el almacenamiento se hace sobre bases de datos, genéricas o desarrolladas a medida.\nActualmente, la tendencia es recoger los datos o bien de forma automática, o bien de forma manual sobre sistemas informatizados (pantallas), lo que permite eliminar el papel y disponer directamente de los datos en un formato digitalizado.\nEn la actualidad, la mayoría de los equipos y líneas de producción se interconectan con los sistemas de información (ver IoT) y almacenan en tiempo real todos los datos necesarios, lo que libera al operario de la pesada tarea de reintroducirlos manualmente, a la vez que reduce los errores debidos a la imputación incorrecta.\nEn todos los casos, es imprescindible asegurar que los sistemas de información pueden exportar sus datos a ficheros de texto tipo fichero plano o tipo CSV, de forma que podamos importarlos tanto a Excel como a R, como veremos más adelante. Estos sistemas de exportación de datos deben diseñarse de forma flexible y abierta, para que tanto la captura como la exportación puedan modificarse y adaptar la recogida de la información a las necesidades de cada momento.\nEn este libro trataremos exclusivamente de lo que llamaremos datos rectangulares: grupos de valores que están asociados a una o más variables, y a varias observaciones. Hay muchos más datos que no se ajustan a esta organización tabular, es el caso de imágenes, sonidos o archivos documentales de texto. Pero la forma más común de almacenar datos industriales es la de las tablas rectangulares, organizadas según el principio de los datos arreglados, que detallaremos en el siguiente capítulo.\n\n\n2.2.2 El uso correcto de una hoja de cálculo en el análisis de datos industriales\n[…]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Herramientas para el análisis. La reproducibilidad.</span>"
    ]
  },
  {
    "objectID": "020-herramientas.html#el-software-estadístico-r",
    "href": "020-herramientas.html#el-software-estadístico-r",
    "title": "2  Herramientas para el análisis. La reproducibilidad.",
    "section": "2.3 El software estadístico R",
    "text": "2.3 El software estadístico R\nR es un lenguaje de programación y un entorno de software utilizado para el análisis estadístico, la visualización de datos y la modelización. Algunas de las características clave de R son:\n\nAmplio espectro de funcionalidades: R abarca una amplia gama de herramientas y paquetes diseñados para realizar diversos análisis estadísticos, exploración de datos y modelización.\nHerramientas gráficas: R dispone de algunas de las bibliotecas gráficas más potentes para la exploración y descripción de datos.\nEstadística descriptiva: R ofrece funciones para calcular estadísticas descriptivas básicas, como la media, mediana, desviación estándar, varianza, rango, cuartiles y percentiles. Estas funciones son esenciales para explorar y resumir datos.\nContrastes de hipótesis: R proporciona funciones para realizar pruebas estadísticas, como t-tests, test chi-cuadrado, ANOVA y pruebas no paramétricas. Estas pruebas permiten evaluar hipótesis y comparar grupos de datos.\nDistribuciones de probabilidad: R incluye una amplia variedad de funciones para trabajar con distribuciones de probabilidad (por ejemplo, normal, uniforme, binomial, Poisson). Esto es útil para generar números aleatorios, calcular probabilidades y cuantiles.\nBibliotecas de funciones (librerías): Además de las amplias funciones básicas de las que dispone, R es capaz de utilizar bibliotecas de funciones (llamadas librerías) que han sido desarrolladas por los propios usuarios, y que amplían sus funcionalidades a todos los campos imaginables, desde el análisis genético al análisis de riesgos bancarios o el control estadístico de procesos.\n\n\n2.3.1 Usos y aplicaciones de R en la estadística industrial\nEn el contexto de la estadística industrial, R se utiliza para:\n\nControl de calidad: R permite analizar datos de procesos industriales, identificar desviaciones y controlar la calidad de los productos.\nOptimización de procesos: Mediante técnicas estadísticas avanzadas, R ayuda a optimizar procesos industriales, reducir costos y mejorar la eficiencia.\nAnálisis de fiabilidad: R se utiliza para evaluar la confiabilidad de sistemas y componentes en la industria.\n\n\n\n2.3.2 Utilización práctica de R en el entorno industrial\n[..a desarrollar..]\n\nImportación de datos y exportación de datos\nManipulación de datos: depuración, corrección, filtrado de datos.\nExploración gráfica de los datos\nAnálisis estadísticos específicos.\nGráficos de control\nInformes automatizados",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Herramientas para el análisis. La reproducibilidad.</span>"
    ]
  },
  {
    "objectID": "020-herramientas.html#otras-herramientas-python-julia",
    "href": "020-herramientas.html#otras-herramientas-python-julia",
    "title": "2  Herramientas para el análisis. La reproducibilidad.",
    "section": "2.4 Otras herramientas: Python, Julia",
    "text": "2.4 Otras herramientas: Python, Julia\nTanto Python como Julia son excelentes alternativas a R en el análisis de datos industriales y la estadística industrial, cada uno con sus propias ventajas:\n\n2.4.1 Python\nPython es uno de los lenguajes de programación más populares en el análisis de datos industriales debido a su versatilidad y la amplia disponibilidad de bibliotecas como pandas, NumPy, SciPy, scikit-learn y Matplotlib. Su integración con otras tecnologías (como bases de datos y servicios en la nube) y su facilidad de uso lo convierten en una opción preferida para tareas de análisis de datos, machine learning y visualización de datos.\n\nVentajas:\n\nVersatilidad: Más allá del análisis de datos, Python es un lenguaje generalista con una amplia gama de aplicaciones, desde desarrollo web hasta machine learning. Esto lo convierte en una herramienta altamente versátil para diversas tareas industriales.\nEcosistema de librerías: Cuenta con una vasta colección de librerías especializadas en ciencia de datos (Pandas, NumPy, SciPy), machine learning (Scikit-learn, TensorFlow), y visualización (Matplotlib, Seaborn).\nIntegración con otras tecnologías: Se integra fácilmente con otros lenguajes y herramientas, lo que facilita la automatización de procesos y la construcción de pipelines de datos.\nComunidad activa: Tiene una comunidad enorme y en constante crecimiento, lo que significa una gran cantidad de recursos, tutoriales y soporte disponible.\n\nRecientemente, Microsoft ha introducido una nueva funcionalidad que permite a los usuarios escribir código Python directamente en las celdas de Excel. Esta integración permite a los usuarios aprovechar la potencia de Python para procesar datos en Excel, realizar cálculos complejos y visualizar datos mediante gráficos de matplotlib insertados directamente en la hoja de cálculo. Para usar esta funcionalidad, los usuarios pueden seleccionar una celda y, en la pestaña Fórmulas, seleccionar Insertar Python. También se puede habilitar Python en una celda escribiendo =PY y eligiendo PY en el menú de autocompletar.\n\n\n\n2.4.2 Julia\nJulia es un lenguaje más reciente, diseñado específicamente para el cálculo numérico y la ciencia de datos. Ofrece un rendimiento cercano al de lenguajes de bajo nivel como C, pero con la sintaxis y facilidad de uso de lenguajes de alto nivel como Python y R. Julia es especialmente útil en aplicaciones donde el rendimiento es crítico, como en simulaciones industriales y análisis de grandes volúmenes de datos.\n\nVentajas\n\nRendimiento: Diseñado específicamente para computación numérica de alto rendimiento, Julia ofrece velocidades comparables a lenguajes compilados como C o Fortran, pero con una sintaxis más cercana a los lenguajes de scripting. Es excelente para cálculos numéricos intensivos y proporciona soporte nativo para paralelismo y computación distribuida.\nSintaxis expresiva: Su sintaxis es intuitiva y similar a la de lenguajes matemáticos, lo que facilita la escritura de código conciso y legible.\nInteroperabilidad: Permite llamar a código escrito en otros lenguajes como C, Python o R, lo que facilita la integración con herramientas existentes.\nEn crecimiento: Aunque más joven que Python y R, Julia está ganando rápidamente popularidad en la comunidad científica y de datos.\n\n\nEn resumen, mientras que R sigue siendo una opción poderosa y preferida para la estadística industrial, Python y Julia se presentan como alternativas viables y, en algunos casos, superiores, dependiendo de los requisitos específicos del proyecto.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Herramientas para el análisis. La reproducibilidad.</span>"
    ]
  },
  {
    "objectID": "020-herramientas.html#el-concepto-de-reproducibilidad",
    "href": "020-herramientas.html#el-concepto-de-reproducibilidad",
    "title": "2  Herramientas para el análisis. La reproducibilidad.",
    "section": "2.5 El concepto de reproducibilidad",
    "text": "2.5 El concepto de reproducibilidad\nLa reproducibilidad de un ensayo o experimento es la capacidad de ser reproducido o replicado por otros, en particular, por la comunidad científica. La reproducibilidad se refiere a la capacidad de obtener resultados consistentes al replicar un estudio o experimento utilizando los mismos datos, metodología original y, en su caso, el mismo código informático empleado para los análisis.En otras palabras, cuando se replica un análisis de datos o un experimento, los resultados deben ser alcanzados nuevamente con un alto grado de confiabilidad.\nLa repetibilidad o replicabilidad se refiere a la posibilidad de obtener resultados consistentes al replicar un estudio con un conjunto distinto de datos, pero obtenidos siguiendo el mismo diseño experimental. Implica obtener resultados consistentes utilizando nuevos datos o nuevos resultados computacionales para responder a la misma pregunta científica.\nEl químico irlandés Robert Boyle, en el siglo XVII, subrayó la importancia de la reproducibilidad en la ciencia. Boyle sostenía que los fundamentos del conocimiento debían basarse en hechos producidos experimentalmente, que pudieran volverse creíbles para la comunidad científica por su reproducibilidad. La bomba de aire de Boyle, un aparato científico complicado y costoso en ese momento, condujo a una de las primeras disputas documentadas sobre la reproducibilidad de un fenómeno científico.\n\n2.5.1 Importancia en la Ciencia\nLa reproducibilidad es esencial para la investigación científica, ya que permite validar y verificar los resultados obtenidos. En las últimas décadas, ha habido una creciente preocupación por la falta de reproducibilidad en muchos resultados científicos publicados, lo que ha llevado a una crisis de reproducibilidad o replicación. La reproducibilidad garantiza que los resultados científicos sean confiables y puedan ser validados por otros investigadores. Es un pilar fundamental para el avance del conocimiento en todas las disciplinas.\n\n\n2.5.2 Reproducibilidad en metrología\nEn metrología, la reproducibilidad es la capacidad de un instrumento de dar el mismo resultado en mediciones diferentes, realizadas en las mismas condiciones a lo largo de periodos dilatados de tiempo. Esta cualidad debe evaluarse a largo plazo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Herramientas para el análisis. La reproducibilidad.</span>"
    ]
  },
  {
    "objectID": "020-herramientas.html#ventajas-de-r-frente-a-la-hoja-de-cálculo-en-la-reproducibilidad-de-un-análisis",
    "href": "020-herramientas.html#ventajas-de-r-frente-a-la-hoja-de-cálculo-en-la-reproducibilidad-de-un-análisis",
    "title": "2  Herramientas para el análisis. La reproducibilidad.",
    "section": "2.6 Ventajas de R frente a la hoja de cálculo en la reproducibilidad de un análisis",
    "text": "2.6 Ventajas de R frente a la hoja de cálculo en la reproducibilidad de un análisis\nLas ventajas de utilizar R en lugar de hojas de cálculo tradicionales (como Microsoft Excel) incluyen:\n\nCódigo abierto (scripts): R permite crear flujos de trabajo basados en código, lo que mejora la reproducibilidad de los análisis y facilita la colaboración entre investigadores. Puedes escribir scripts en R para automatizar tareas y asegurar la reproducibilidad. Los scripts son transparentes y pueden ser compartidos y verificados por otros investigadores.\nFlexibilidad estadística: R es especialmente útil para técnicas avanzadas de análisis, lo que lo convierte en una excelente opción para investigadores que buscan análisis de vanguardia.\nCapacidad para tratar grandes cantidades de datos: R puede manejar grandes conjuntos de datos sin problemas, lo que es fundamental en la estadística industrial.\nPrecisión: R está diseñado específicamente para análisis estadístico, lo que lo hace más preciso que Excel en ciertos casos, como en análisis de regresión lineal.\nCapacidad avanzada: R ofrece una amplia gama de paquetes y funciones para realizar análisis estadísticos avanzados, como modelos lineales, series temporales, análisis multivariante y más.\n\nPor su parte, la hoja de cálculo tiene una curva de aprendizaje más sencilla y es en general más fácil de usar, pero tiene algunos inconvenientes:\n\nInexactitudes: Estudios han demostrado que Excel puede mostrar ciertas inexactitudes en análisis de regresión lineal y otros métodos estadísticos.\nLimitaciones estadísticas: Excel no está diseñado específicamente para análisis estadístico avanzado, por lo que puede carecer de algunas capacidades necesarias para investigaciones más complejas.\nFalta de transparencia para la auditoría: Las fórmulas y cálculos en Excel pueden ser difíciles de rastrear y verificar, lo que afecta la reproducibilidad.\n\nPor estas razones usaremos Excel para el almacenamiento de datos y el análisis básico, y usaremos R para el análisis gráfico más detallado y el análisis numérico y estadístico.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Herramientas para el análisis. La reproducibilidad.</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html",
    "href": "030-organizacion.html",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "",
    "text": "3.1 Etapas en un flujo de trabajo estructurado.\nUn flujo de trabajo en análisis de datos es un proceso sistemático y estructurado que guía la manipulación, exploración y análisis de datos desde su recolección hasta la obtención de resultados finales y su comunicación. Es una hoja de ruta que asegura que cada paso se realice de manera ordenada, eficiente y reproducible, facilitando la comprensión y utilización de los datos.\nHadley Wickham (Garret Grolemund Hadley Wickham Mine Çetinkaya-Rundel 2023) ha propuesto un método de flujo de trabajo que se ha convertido en estándar en la ciencia de datos (hay versión en español: (Garret Grolemund Hadley Wickham 2023))\nEste flujo de trabajo abarca diversas actividades como la importación de datos, su limpieza y transformación, el análisis exploratorio, y el modelado, culminando en la interpretación y presentación de los resultados. Todo esto se hace siguiendo metodologías específicas para asegurar la calidad y precisión del análisis.\nLa importancia de seguir un flujo de trabajo bien definido radica en la capacidad de replicar estudios, minimizar errores y fomentar la transparencia, permitiendo que cualquier persona pueda entender y validar las decisiones tomadas durante el análisis. Además, mejora la eficiencia al estandarizar procedimientos y facilita la colaboración entre diferentes analistas o equipos de trabajo.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html#etapas-en-un-flujo-de-trabajo-estructurado.",
    "href": "030-organizacion.html#etapas-en-un-flujo-de-trabajo-estructurado.",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "",
    "text": "3.1.1 Recolección de datos\nLa primera etapa es la recolección de datos. Esto implica obtener datos desde diversas fuentes como archivos CSV, bases de datos, APIs, etc. La recolección de datos es fundamental porque la calidad del análisis depende de la calidad de los datos recolectados.\n\n\n3.1.2 Inspección de los datos\nUna vez recolectados, se procede a inspeccionar los datos para entender su estructura y contenido. Esto incluye examinar los tipos de datos, la presencia de valores faltantes, duplicados y la distribución de las variables.\n\n\n3.1.3 Limpieza de los datos\nLa limpieza de datos es crucial para asegurar que la información sea precisa y esté en el formato adecuado. Esta etapa incluye:\n\nManejo de valores faltantes.\nEliminación de duplicados.\nCorrección de inconsistencias.\nTransformación de datos a un formato adecuado para el análisis.\n\n\n\n3.1.4 Transformación de los datos\nTransformar los datos a un formato ordenado o arreglado (tidy) es esencial. Según Wickham, los datos arreglados tienen una estructura clara: cada variable es una columna, cada observación es una fila, y cada valor tiene su propia celda. Este formato facilita el análisis y la visualización de datos.\n\n\n3.1.5 Análisis exploratorio de datos (EDA)\nEl Análisis Exploratorio de Datos (EDA) busca entender los patrones y relaciones en los datos mediante estadísticas descriptivas y visualizaciones. Durante esta etapa se realizan:\n\nEstadísticas básicas (media, mediana, desviación estándar).\nGráficos y diagramas para visualizar la distribución de los datos y las relaciones entre variables.\n\n\n\n3.1.6 Modelado de datos\nDependiendo del objetivo del análisis, se pueden aplicar diversos modelos estadísticos para extraer información y hacer predicciones. Esto puede incluir:\n\nModelos de regresión.\nAnálisis de clasificación.\nModelos de series temporales, entre otros.\n\n\n\n3.1.7 Comunicación de resultados\nFinalmente, es fundamental comunicar los resultados de manera clara y efectiva. Esto se hace a través de:\n\nTablas y resúmenes interpretativos.\nGráficos y visualizaciones.\nInformes y presentaciones que expliquen los hallazgos y sus implicaciones.\n\nSiguiendo estos pasos, puedes manejar y analizar datos de manera organizada y reproducible, facilitando la colaboración y la toma de decisiones informadas. Este flujo de trabajo asegura que los datos se traten de manera sistemática, desde su recolección hasta la comunicación de los resultados.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html#razones-para-seguir-un-flujo-de-trabajo",
    "href": "030-organizacion.html#razones-para-seguir-un-flujo-de-trabajo",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "3.2 Razones para seguir un flujo de trabajo",
    "text": "3.2 Razones para seguir un flujo de trabajo\n\nReproducibilidad: Un flujo de trabajo organizado permite que los análisis sean reproducibles. Otros pueden seguir los mismos pasos para obtener resultados similares, lo que es crucial en la investigación y en la toma de decisiones basadas en datos.\nConsistencia: Ayuda a asegurar que los pasos se realizan de manera consistente cada vez que se ejecuta el análisis, reduciendo la posibilidad de errores humanos.\nTransparencia: Proporciona un registro claro de los pasos tomados durante el análisis, facilitando la revisión y validación de los resultados.\nEficiencia: Mejora la eficiencia al estandarizar el proceso, permitiendo a los analistas concentrarse en el análisis y la interpretación de los datos en lugar de tareas repetitivas.\nColaboración: Facilita la colaboración entre equipos, ya que los flujos de trabajo bien documentados permiten que otros comprendan fácilmente los métodos y pasos utilizados.\nAdaptabilidad: Permite adaptar y ajustar el análisis de manera más fácil cuando se presentan nuevos datos o cuando cambian los objetivos del análisis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html#problemas-de-no-seguir-un-flujo-de-trabajo-estructurado",
    "href": "030-organizacion.html#problemas-de-no-seguir-un-flujo-de-trabajo-estructurado",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "3.3 Problemas de no seguir un flujo de trabajo estructurado",
    "text": "3.3 Problemas de no seguir un flujo de trabajo estructurado\n\nErrores y Sesgos: La falta de un enfoque estructurado puede resultar en errores y sesgos inadvertidos en el análisis, lo que puede llevar a conclusiones incorrectas.\nDificultad para Replicar Resultados: Sin un flujo de trabajo claro, replicar resultados se vuelve complicado, lo que puede afectar la credibilidad del análisis y la capacidad de validación por otros.\nFalta de Documentación: La ausencia de una documentación adecuada dificulta entender los pasos y las decisiones tomadas durante el análisis, lo que puede ser un obstáculo en auditorías y revisiones.\nIneficiencia: Sin una estructura clara, los analistas pueden gastar tiempo valioso realizando tareas repetitivas y resolviendo problemas que podrían haberse evitado con un enfoque más organizado.\nProblemas de Colaboración: La colaboración se vuelve más difícil si los miembros del equipo no pueden seguir o entender los pasos tomados por otros, lo que puede llevar a malentendidos y duplicación de esfuerzos.\nDificultad para Adaptarse a Cambios: Sin un flujo de trabajo definido, adaptar el análisis a nuevos datos o cambios en los objetivos puede ser más complejo y propenso a errores.\n\nEn resumen, seguir un flujo de trabajo estructurado es esencial para garantizar la precisión, eficiencia, y reproducibilidad del análisis de datos, evitando problemas que puedan comprometer la integridad y utilidad de los resultados. .",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html#un-ejemplo-revisando-los-datos-existentes.",
    "href": "030-organizacion.html#un-ejemplo-revisando-los-datos-existentes.",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "3.4 Un ejemplo: revisando los datos existentes.",
    "text": "3.4 Un ejemplo: revisando los datos existentes.\nCuando nos incorporamos a un equipo de trabajo existente, lo más seguro es que ya se disponga de un sistema de archivo de los datos, de acuerdo con los métodos habituales del equipo. En muchos casos, el diseño de la captura de datos sigue aproximadamente el modelo manual en papel; se introducen los datos en la hoja de cálculo y una vez completados, se imprime el documento para su archivo.\nEl error más común que se suele cometer es, precisamente, tratar la hoja de cálculo como un bloc de notas, es decir, hacer anotaciones de forma libre, colocar los datos y el resultado de los análisis al lado y en cualquier parte de la hoja, y apoyarnos en el contexto para interpretar lo que hemos guardado. Pero para que el ordenador sea capaz de analizar nuestros datos de manera eficiente, debemos estructurarlos de tal forma que el programa use la información tal como nosotros queremos.\nEs común utilizar una hoja para guardar múltiples tablas de datos, tal como vemos en la Figura 3.1. Esta estructura, sin embargo, resulta enormemente confusa para su análisis, o lo imposibilita completamente.\n\n\n\n\n\n\nFigura 3.1: Hoja Excel desordenada: ¡No hagas esto!\n\n\n\nEn otros casos, los datos se guardan en hojas de cálculo que se componen de diferentes pestañas para cada semana, cada mes o cada año, como vemos en la Figura 3.2. Sin embargo, esta forma de almacenar los datos tampoco es la óptima para su análisis.\n\n\n\n\n\n\nFigura 3.2: Hoja Excel con una estructura no ordenada\n\n\n\nSi las diferentes tablas presentan situaciones diferentes, o datos que no están relacionados, podemos utilizar diferentes pestañas. Pero si los datos están vinculados, por ejemplo, se corresponden con las mismas medidas, hechas en fechas diferentes (meses, años), la respuesta es que las pestañas no son la forma correcta de almacenarlos datos; lo mejor es añadir una variable que nos permita diferenciar los datos por fecha; nuestro programa de análisis nos permitirá filtrar los datos según la fecha que deseemos, y todos estarán en una única tabla, facilitando la coherencia y el análisis posterior.\nHay muchas formas de almacenar la información en una hoja de cálculo, pero sólo la estructura de datos ordenados o arreglados facilita la utilización de los datos tanto por la hoja de cálculo como por otros programas de análisis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html#los-datos-ordenados-o-arreglados-tidy-data",
    "href": "030-organizacion.html#los-datos-ordenados-o-arreglados-tidy-data",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "3.5 Los datos ordenados o arreglados (tidy data)",
    "text": "3.5 Los datos ordenados o arreglados (tidy data)\nDe la misma manera que la gramática permite ordenar y estructurar un escrito de acuerdo a reglas comunes, hay reglas para que el almacenamiento de los datos sea lo más homogéneo posible y se reduzcan los errores al mínimo.\nLas reglas principales al almacenar nuestros datos en una hoja de cálculo son tres:\n\ncolumnas=variables,\nfilas=observaciones,\nceldas=valores.\n\nCada variable debe tener su propia columna, cada observación debe tener su propia fila, y cada valor debe tener su propia celda o casilla .\nEstas tres reglas básicas son las que hacen que nuestro conjunto de datos sea ordenado (o arreglado)(Garret Grolemund Hadley Wickham Mine Çetinkaya-Rundel 2023) (hay edición online en español: (Garret Grolemund Hadley Wickham 2023):\nLa Figura 3.3 muestra estas reglas de forma visual.\n\n\n\n\n\n\nFigura 3.3: Sigue estas tres reglas para tener un conjunto de datos ordenado: las variables están en columnas, las observaciones están en filas, y los valores están en celdas. Fuente de la imagen: Garret Grolemund Hadley Wickham Mine Çetinkaya-Rundel (2023)\n\n\n\nEstas tres reglas están interrelacionadas porque es imposible satisfacer sólo dos de tres.\nEn una hoja de cálculo, una tabla de datos arreglada tendría este aspecto:\n\n\n\n\n\n\nFigura 3.4: Hoja Excel con estructura rectangular de datos ordenados\n\n\n\nDatos rectangulares: formato tabla",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html#qué-es-un-fichero-plano-y-un-fichero-csv",
    "href": "030-organizacion.html#qué-es-un-fichero-plano-y-un-fichero-csv",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "3.6 Qué es un fichero plano y un fichero CSV",
    "text": "3.6 Qué es un fichero plano y un fichero CSV\nSe suele llamar fichero plano a un fichero de datos de texto sin ningún tipo de formato, donde los datos están separados por espacios o tabulaciones. Muchos equipos automáticos, como balanzas de laboratorio o básculas de proceso, producen ficheros planos de texto, que se pueden importar a Excel o R. Un fichero CSV es un fichero plano en el que los valores están separados por un carácter especial, llamado separador. Este separador puede ser una coma , (cuando los decimales se separan mediante un punto, como en EEUU) o un punto y coma ; (cuando los decimales se separan mediante una coma, como en España)\n\n\n\n\n\n\n\n\nFichero plano\n\n\n\n\n\n\n\nFichero CSV separado por puntos y comas\n\n\n\n\n\n\n\n\n\nFichero CSV separado por comas\n\n\n\n\n\n\nFigura 3.5: Tres tipos de ficheros planos de texto.\n\n\n\nEn un fichero plano o en un fichero CSV, la primera fila puede contener los nombres de las columnas. En algunos casos, los elementos de texto pueden estar entre comillas. En estos casos, los programas de importación se ocupan de la conversión de formatos.\nLa importación de un fichero CSV en Excel en español es directa si se ha generado con puntos y comas como separador y comas para los decimales; si no es así, nos aparecerá como un fichero plano de texto sin formato, y tendremos que realizar una conversión.\n\n3.6.1 Cómo exportar un fichero CSV desde Excel a R\nUna vez que tenemos nuestros datos en Excel, hay dos formas en las que podemos poner los datos a disposición de R para su análisis: exportarlos a un archivo de texto con formato CSV, o leer directamente los datos de Excel desde R utilizando las funciones de la librería tidyverse. En ambos casos, el resultado en R es un dataframe o cuadro de datos, que es una estructura equivalente a la de nuestra tabla de datos en Excel.\nEn los sistemas operativos que usan por defecto para la numeración el formato europeo (donde el separador decimal es una coma , y el separador de campos es un punto y coma ;), puedes seguir estos pasos en R.\n\n3.6.1.1 Paso 1: Guardar el Fichero CSV desde Excel\n\nAbre tu fichero en Excel.\nSelecciona Archivo &gt; Guardar como.\nElige el formato **CSV (delimitado por comas) (*.csv)**.\nGuarda el archivo.\n\n\n\n3.6.1.2 Paso 2: Importar el CSV en R\nPuedes usar la función read.csv2 de base R o la función read_csv2 del paquete readr, que está optimizado para leer archivos CSV más rápido y con más flexibilidad.\n\n\n3.6.1.3 Usando Base R\n# Leer el CSV con separador de campos \";\" y separador decimal \",\"\ndata &lt;- read.csv2(\"ruta/al/archivo.csv\", header = TRUE, sep = \";\", dec = \",\")\n\n# Ver las primeras filas del dataframe\nhead(data)\n\n\n3.6.1.4 Usando readr\nPrimero, instala y carga el paquete readr:\ninstall.packages(\"readr\")\nlibrary(readr)\n\n# Leer el CSV con separador de campos \";\" y separador decimal \",\"\ndata &lt;- read_csv2(\"ruta/al/archivo.csv\", col_names = TRUE)\n\n# Ver las primeras filas del dataframe\nhead(data)\n\n\n\n3.6.2 Explicación del Código:\n\nread.csv2 / read_csv2: Funciones utilizadas para leer archivos CSV con formato europeo.\n“ruta/al/archivo.csv”: La ruta al archivo CSV que deseas importar.\nheader = TRUE / col_names = TRUE: Indica que el primer fila del CSV contiene los nombres de las columnas.\nsep = “;”: Define el separador de campos como punto y coma ;.\ndec = “,”: Define el separador decimal como coma ,.\n\n\n\n3.6.3 Qué es un DataFrame en R\nUn dataframe es una estructura de datos en R que permite almacenar datos tabulares (similares a una hoja de cálculo o una tabla en una base de datos). Los dataframes son muy flexibles y poderosos para el análisis de datos.\n\n3.6.3.1 Características de un DataFrame:\n\nColumnas: Cada columna puede contener datos de un tipo diferente (numérico, carácter, factor, etc.).\nFilas: Cada fila representa una observación o registro.\nAtributos: Los dataframes tienen atributos como nombres de filas y columnas.\n\n\n\n3.6.3.2 Ejemplo de Creación de un DataFrame\n# Crear un dataframe simple\ndf &lt;- data.frame(\n  Nombre = c(\"Alice\", \"Bob\", \"Carol\"),\n  Edad = c(25, 30, 35),\n  Salario = c(50000, 55000, 60000)\n)\n\n# Ver el dataframe\nprint(df)\n\n\n3.6.3.3 Explicación del Código:\n\ndata.frame(): Función utilizada para crear un dataframe.\nNombre, Edad, Salario: Columnas del dataframe.\nc(): Función para concatenar valores en un vector.\n\n\n\n\n3.6.4 Ejemplo Real de Análisis\nSi ya tienes un archivo CSV que importaste, puedes comenzar a analizar los datos. Aquí hay un ejemplo básico de cómo podrías resumir y visualizar los datos:\n# Instalar y cargar ggplot2 para la visualización\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n# Resumen de los datos\nsummary(data)\n\n# Visualización simple: Histograma de una variable numérica\nggplot(data, aes(x = variable_numerica)) +\n  geom_histogram(binwidth = 1) +\n  labs(title = \"Histograma de la Variable Numérica\",\n       x = \"Valor\",\n       y = \"Frecuencia\")\nEste código proporciona un resumen y una visualización básica de tus datos importados.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "030-organizacion.html#para-resolver",
    "href": "030-organizacion.html#para-resolver",
    "title": "3  La organización de los datos y el flujo de trabajo.Los datos ordenados o arreglados (tidy data)",
    "section": "3.7 Para resolver",
    "text": "3.7 Para resolver\nPoner aquí distintos ejemplos de nombres de variables para ver si son válidos o no. Describir medidas y preguntar cómo llamaríamos a esa variable (por ejemplo, temperatura de la leche que acabamos de descargar de una cisterna)\n\n\n\n\nHadley Wickham, Garret Grolemund. 2023. «R Para Ciencia de Datos». 2023. https://es.r4ds.hadley.nz/.\n\n\nHadley Wickham, Garret Grolemund, Mine Çetinkaya-Rundel. 2023. R for Data Science, 2nd ed. 1005 Gravenstein Highway North, Sebastopol, CA95472: O’Reilly Media Inc. https://r4ds.hadley.nz/.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La organización de los datos y el flujo de trabajo.Los datos ordenados o _arreglados_ (_tidy data_)</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html",
    "href": "040-exploracion.html",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "",
    "text": "4.1 Explorando los datos con Excel y R: un ejemplo.\nEn este capítulo esyudiaremos cómo describir un conjunto de datos de forma visual, utilizando varios tipos de gráficos distintos:\nVeremos la relación visual entre un histograma y un diagrama de caja, y aprenderemos también a construir tablas de frecuencias en Excel y en R. Finalmente, veremos algunos otros tipos de gráficos que son útiles para aplicaciones concretas, como los gráficos de series temporales.\nSupongamos que queremos medir la altura de un grupo de alumnos de nuestra clase. Éste es nuestro grupo:\nRealizamos la medida de altura de cada persona y registramos los valores en una hoja de cálculo, siguiendo las buenas prácticas que hemos visto al estudiar los datos ordenados.\nGuardaremos esta tabla en un archivo CSV y lo importamos a un dataframe de R para su uso a lo largo del capítulo. Utilizamos la opción fileEncoding='latin1' para importar correctamente los caracteres acentuados.\nlibrary(tidyverse)\ndf_aula &lt;- read.csv2(\"excel-R/aula1.csv\",fileEncoding='latin1')\ndf_aula\n\n    nombre altura_cm\n1     Luis       153\n2      Ana       135\n3     Iván       140\n4    Lucía       140\n5  Jessica       175\n6  Antonio       138\n7    Mikel       145\n8    Marta       154\n9   Carmen       152\n10  Javier       159\n11   María       154",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#el-diagrama-de-tallo-y-hojas-stem-and-leaf-plot-o-stemplot",
    "href": "040-exploracion.html#el-diagrama-de-tallo-y-hojas-stem-and-leaf-plot-o-stemplot",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.2 El diagrama de tallo y hojas (stem and leaf plot o stemplot)",
    "text": "4.2 El diagrama de tallo y hojas (stem and leaf plot o stemplot)\nEl stemplot recibe este nombre porque el dibujo que resulta se asemeja a un tallo el que le salen las hojas que son los datos individuales. Para construirlo, quitamos el último dígito a la derecha de nuestros valores y colocamos verticalmente los valores resultantes ordenándolos de menor a mayor, y evitando las repeticiones. Para evitar errores en la escala, debemos incluir los valores intermedios aunque no haya ninguno en nuestros datos (en el ejemplo, el valor 16 que correspondería a los 160). Esto forma el “tallo” de nuestro diagrama:\n\nA continuación añadimos las hojas en la celda a la derecha, que consisten en los valores que hemos “cortado” de nuestro árbol, uno al lado de otro, incluyendo esta vez los valores repetidos, en orden de menor a mayor. Por ejemplo, para el valor 135, descartamos 13 y utlizamos 5; para el valor 138, descartamos 13 y utilizamos 8, y así sucesivamente para todos los valores.\n\nEl diagrama nos dice que nuestros valores son 135, 138, 140, 140, 145, … Podemos ver que los valores en torno a 150 cm son los más frecuentes, y que hay un valor alto (175) que se separa un poco del resto.\nR permite realizar el stemplot mediante la función \\(stem()\\) de forma automática:\n\nstem(df_aula$altura_cm)\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  13 | 58\n  14 | 005\n  15 | 23449\n  16 | \n  17 | 5\n\n\nEl stemplot es muy sencillo de hacer y nos da una visión rápida de la distribución de nuestros valores, así como de la posible existencia de valores que se separan del conjunto. Estos valores alejados, que se conocen en inglés como outliers, tienen mucha importancia en el analisis e interpretación de los datos, como veremos más adelante.\nLa ventaja principal del stemplot es que mantiene los valores originales de las observaciones, y puede hacerse fácilmente con bolígrafo y papel, sin necesidad de más herramientas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#distribuciones-de-frecuencias",
    "href": "040-exploracion.html#distribuciones-de-frecuencias",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.3 Distribuciones de frecuencias",
    "text": "4.3 Distribuciones de frecuencias\nEl stemplot agrupa nuestros valores y nos ayuda a visualizar la frecuencia de cada valor, o, mejor, la frecuencia de valores en el intervalo entre cada valor. Si agrupamos nuestros valores por intervalos, y contamos el número de observaciones que aparecen en cada intervalo, obtenemos una distribución de frecuencias, que puede expresarse de forma absoluta o relativa.\n\nLa frecuencia absoluta es un recuento simple de cuántas veces aparece cada valor en un conjunto de datos.\nLa frecuencia relativa nos muestra la proporción de cada valor frente al total. Puede expresarse como fracción (entre 0 y 1) o como porcentaje (respecto a 100)\n\nLa tabla a continuación muestra una distribución de frecuencias, calculada mediante una tabla dinámica de Excel.\n\nTambién podemos calcular las frecuencias absolutas y relativas en R; en este caso, dado que los intervalos se han calulado de forma ligeramente diferente, las frecuencias calculadas son también ligeramente diferentes de las que hemos obtenido en Excel.\n\nlibrary (tidyverse)\ndf_camembert &lt;- read.csv2(\"excel-R/camembert.csv\",fileEncoding='latin1')\ndf_camembert |&gt;\n  mutate (grupo = cut_interval(est, 4)) |&gt;\n  group_by(grupo) |&gt;\n  summarise (frec_abs = n()) |&gt;\n  mutate(frec_rel = frec_abs / sum(frec_abs))\n\n# A tibble: 4 × 3\n  grupo       frec_abs frec_rel\n  &lt;fct&gt;          &lt;int&gt;    &lt;dbl&gt;\n1 [42.9,45.3]       36   0.171 \n2 (45.3,47.8]      131   0.621 \n3 (47.8,50.2]       41   0.194 \n4 (50.2,52.6]        3   0.0142\n\n\nR utiliza los símbolos ( y [ para definir los intervalos, tal como se hace en matemáticas.\n\nIntervalo abierto: El símbolo ( se utiliza para denotar un intervalo abierto. Por ejemplo,el intervalo \\((a, b)\\) representa todos los números reales mayores que \\(a\\) y menores que \\(b\\) (excluye los valores \\(a\\) y \\(b\\)).\nIntervalo cerrado o semiabierto:El símbolo [ se utiliza para denotar un intervalo cerrado o semiabierto. Por ejemplo:\n\n\\([a, b]\\) representa todos los números reales mayores o iguales que \\(a\\) y menores o iguales que \\(b\\) (incluye \\(a\\) y \\(b\\)).\n\\([a, b)\\) representa todos los números reales mayores o iguales que \\(a\\) y menores que \\(b\\) (incluye \\(a\\), pero excluye \\(b\\)).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#diagramas-de-barra-e-histogramas",
    "href": "040-exploracion.html#diagramas-de-barra-e-histogramas",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.4 Diagramas de barra e histogramas",
    "text": "4.4 Diagramas de barra e histogramas\nCuando nuestra variable es discreta, podemos representar las frecuencias de cada valor de forma gráfica utilizando un diagrama de barras. Este diagrama utiliza barras rectangulares para representar la frecuencia de cada categoría.\nUn histograma es un diagrama que utiliza las barras rectangulares para hacer un gráfico de la distribución de valores continuos, agrupados en clases. La anchura de esos grupos o clases (en inglés, bins), puede variarse, lo que cambia el perfil del gráfico obtenido.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#histogramas-en-excel",
    "href": "040-exploracion.html#histogramas-en-excel",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.5 Histogramas en Excel",
    "text": "4.5 Histogramas en Excel\nLa tabla dinámica que hemos construido en Excel ha transformado nuestra variable continua, altura_cm, en una variable discreta, al agrupar los valores en intervalos. Si representamos las frecuencias absolutas de nuestra tabla dinámica anterior, el diagrama resultante sería éste:\n\nEn el caso de la tabla dinámica, Excel no construye el diagrama de barras a partir de la tabla de los valores originales, sino de las categorías de la tabla dinámica. Dado que estas categorías (los grupos que ha formado la tabla dinámica) son discretas, Excel utiliza el resultado de la tabla dinámica para hacer el gráfico con un diagrama de barras.\nEste diagrama muestra su utilidad cuando representamos la distribución de un conjunto de valores más grande que nuestros once alumnos. Veamos su aplicación a los datos diarios de una fabricación de queso camembert a lo largo de un año.\nLa tabla de datos tiene esta estructura:\n\nAunque no se muestran en la figura, la tabla está formada por 211 casos. Analicemos los datos con Excel. Los pasos son:\n\nConstruir la tabla dinámica\nAgrupar los datos\nInsertar el gráfico a partir de la tabla\n\nCon una agrupación de datos en intervalos de 1, esta es nuestra tabla dinámica:\n\n\nSi nuestro intervalo de clase fuese de 2 puntos de extracto seco en vez de 1, el histograma tendría este aspecto:\n\nSi por el contrario hubiésemos agrupado en intervalos de 0,5 puntos, el histograma sería este:\n\nLa decisión de agrupar las variables continuas en intervalos de diferentes anchuras tiene efectos sobre el aspecto del gráfico; no obstante, debemos ser capaces de interpretar que la distribución de los valores es la misma en los tres casos: hay una mayoría de casos con valores entre 46 y 48, y muy pocos casos con valores muy bajos o muy altos. En este caso, la distribución de los valores es aproximadamente simétrica, y se reparten alrededor de una mayoría de valores centrales.\nEn otras ocasiones, nos encontramos con datos que son asimétricos: hay una mayoría de valores bajos o bien de valores altos. Veamos un caso: los recuentos bacterianos de bacterias coliformes, que tenemos en la última columna a la derecha de nuestra tabla, en la variable ´coliformes´.\n\nEn este caso, vemos que la mayoría de los casos tienen valor cero. Es el caso de los recuentos de bacterias contaminantes, en el que la mayoría de los análisis tienen recuentos cero o muy bajos, y sólo en pocos casos tienen valores altos. Veremos con más detalle cómo tratar estas distribuciones cuando hablemos de las distribuciones de probabilidad, en capítulos posteriores.\nComo vemos, aunque Excel utiliza el diagrama de barras para construir el gráfico, en realidad estamos construyendo un histograma, en dos etapas: agrupación de los datos y creación del gráfico. Al construir un histograma en R, el programa realiza automáticamente ambos pasos. Para verlo por partes, vamos a construir la tabla de frecuencias y el histograma en R.\n\ndf_camembert |&gt;\n  mutate (grupo = cut_width(est, width=1, boundary=1)) |&gt;\n  group_by(grupo) |&gt;\n  summarise (frec_abs = n()) |&gt;\n  mutate(frec_rel = frec_abs / sum(frec_abs))\n\n# A tibble: 10 × 3\n   grupo   frec_abs frec_rel\n   &lt;fct&gt;      &lt;int&gt;    &lt;dbl&gt;\n 1 [42,43]        1  0.00474\n 2 (43,44]        4  0.0190 \n 3 (44,45]       23  0.109  \n 4 (45,46]       48  0.227  \n 5 (46,47]       56  0.265  \n 6 (47,48]       49  0.232  \n 7 (48,49]       17  0.0806 \n 8 (49,50]       10  0.0474 \n 9 (50,51]        2  0.00948\n10 (52,53]        1  0.00474\n\n\nR tiene una función básica, la función hist(), que construye el histograma directamente sin necesidad de hacer previamente una tabla de frecuencias (en realidad, la tabla de frecuencias se calcula internamente).\nhist(df_camembert$est)\n\ndf_camembert |&gt;\n  ggplot(aes(x=est)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n(a) Función básica de R\n\n\n\n\n\n\n\n\n\n\n\n(b) Función ggplot()\n\n\n\n\n\n\n\nFigura 4.1: Ejemplos de histogramas\n\n\n\nEn general, son más útiles las opciones de la función ggplot(), en la biblioteca tidyverse.\nEn los histogramas de los recuentos bacterianos,utilizamos una opción para aumentar el número de barras que queremos en el histograma: breaks= en la función base, bins= en ggplot():\nhist(df_camembert$coliformes, breaks=50)\n\ndf_camembert |&gt;\n  ggplot(aes(x=coliformes)) +\n    geom_histogram(bins=50)\n\n\n\n\n\n\n\n\n\n\n\n(a) Función básica de R\n\n\n\n\n\n\n\n\n\n\n\n(b) Función ggplot()\n\n\n\n\n\n\n\nFigura 4.2: Ejemplos de histogramas\n\n\n\nEn casos de distribuciones muy asimétricas, a veces es conveniente aplicar una transformación a los datos, tal como el logaritmo decimal, mediante la función log10(); esto facilita la interpretación del gráfico:\n\ndf_camembert |&gt;\n  ggplot(aes(x=log10(coliformes+1))) +\n    geom_histogram(bins=50)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#gráficos-de-densidad",
    "href": "040-exploracion.html#gráficos-de-densidad",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.6 Gráficos de densidad",
    "text": "4.6 Gráficos de densidad\nUn gráfico de densidad en R es una representación visual suavizada de la distribución de un conjunto de datos. A diferencia de los histogramas, que dividen los datos en intervalos y cuentan las frecuencias, los gráficos de densidad utilizan técnicas estadísticas no paramétricas para estimar la función de densidad de probabilidad.\nExcel no permite la representación de los gráficos de densidad; en R pueden hacerse con la función ggplot()simplemente añadiendo la geometría geom_density()\ndf_camembert |&gt;\n  ggplot(aes(x=est)) +\n    geom_density()\n\ndf_camembert |&gt;\n  ggplot(aes(x=log(coliformes+1))) +\n    geom_density()\n\n\n\n\n\n\n\n\n\n\n\n(a) EST\n\n\n\n\n\n\n\n\n\n\n\n(b) coliformes\n\n\n\n\n\n\n\nFigura 4.3: Ejemplos de diagramas de densidad\n\n\n\nPodemos representar simultáneamente el histograma y la función de densidad:\n\ndf_camembert |&gt;\n  ggplot(aes(x=est)) +\n    geom_histogram(aes(y = ..density..), bins = 20, fill = \"lightblue\", color = \"black\") +\n    geom_density(color = \"red\", size = 1) +\n    labs(title = \"Histograma y densidad\", x = \"Valores\", y = \"Densidad\")\n\n\n\n\n\n\n\n\nLa ventaja de los gráficos de densidad es que como no tenemos que fraccionar los datos en intervalos arbitrarios, no estamos afectados por el efecto visual de la anchura de estos intervalos. También hay otras ventajas desde el punto de vista estadístico, que veremos al hablar de las distribuciones de probabilidad.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#diagramas-de-caja-boxplot-y-resumen-de-cinco-números.",
    "href": "040-exploracion.html#diagramas-de-caja-boxplot-y-resumen-de-cinco-números.",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.7 Diagramas de caja (boxplot) y resumen de cinco números.",
    "text": "4.7 Diagramas de caja (boxplot) y resumen de cinco números.\nEste gráfico fue creado por el estadístico John Tukey en 1977, y es una herramienta fundamental en la exploración de datos. Se basa en un grupo de medidas que se utiliza ampliamente en la descripción de conjuntos de datos, el conjunto de cuartiles. Si dividimos un grupo de datos ordenados en cuatro partes iguales, mediante tres puntos de corte, llamamos primer cuartil o \\(Q1\\) al valor que se situa en el 25%; segundo cuartil, o \\(Q2\\), al valor que se sitúa en el centro (50%), y tercer cuartil, o \\(Q3\\), al punto que se situa en el 75% de los datos. A estos tres valores añadimos el mínimo y el máximo, y tenemos un conjunto de cinco números que nos permiten describir la forma de la distribución de datos con cierta precisión. El segundo cuartil (\\(Q2\\)), que corresponde al 50% de los datos, se conoce habitualmente como mediana. El valor resultante de restar \\(Q3-Q1\\) es lo que se conoce como rango intercuartil o \\(IQR\\), y es una medida de la dispersión de la distribución de datos (mide la amplitud de la distribución).\nEl diagrama de caja, también conocido como boxplot, es un gráfico que permite resumir las características principales de un conjunto de datos utilizando estos cinco números, tal como se explica a continuación. Sus ventajas son:\n\nMuestra la mediana y los cuartiles (Q1 y Q3) de los datos.\nPermite identificar la simetría de la distribución: si la mediana no está en el centro, la distribución no es simétrica.\nPermite detectar posibles valores atípicos, representando los valores atípicos (outliers) que están lejos del resto de los datos (un valor es atípico si está más allá de (Q3 + 1.5 IQR) o (Q1 - 1.5 IQR).\n\nLa construcción de un diagrama de caja es como sigue:\n\nMicrosoft Excel no dispone de un diseño de gráficos de caja que sea práctico, por lo que recurriremos siempre a R para realizarlos.\nComo casi siempre, hay una función de base que dibuja un boxplot y también una geometría de ggplot()que lo hace: geom_boxplot(), con muchas más opciones de diseño y formato que la opción de base.\n\nboxplot(df_aula$altura_cm)\n\n\n\n\n\n\n\nFigura 4.4: Boxplot con los gráficos básicos de R\n\n\n\n\n\nVamos a repetir el gráfico para los datos de producción de queso camembert, usando ahora los gráficos básicos y los de ggplot():\ndf_camembert &lt;- read.csv2(\"excel-R/camembert.csv\",fileEncoding='latin1')\ndf_camembert$fecha &lt;- as.Date(df_camembert$fecha, format(\"%d/%m/%Y\"))\n\nboxplot(df_camembert$est)\n\ndf_camembert |&gt;\n  ggplot(aes(x=\"\", y=est))+\n  geom_boxplot() +\n  theme_bw() +\n  theme(axis.text.x = element_blank(),  # Oculta las etiquetas del eje x\n        axis.ticks.x = element_blank()) # Oculta las marcas del eje x\n\n\n\n\n\n\n\n\n\n\n\n(a) Boxplot básico de R\n\n\n\n\n\n\n\n\n\n\n\n(b) Boxplot utilizando ggplot()\n\n\n\n\n\n\n\nFigura 4.5: Ejemplos de boxplot\n\n\n\nUn uso muy interesante del boxplot en R consiste en agrupar los boxplot de una variable en funcion de otra. En este caso, agrupamos el extracto seco por meses previa agrupación de la fecha. Esta agrupación puede hacerse tanto en los gráficos básicos de R como en ggplot():\ndf_camembert$mes &lt;- format(df_camembert$fecha, \"%m\")\nboxplot (df_camembert$est~df_camembert$mes)\n\ndf_camembert |&gt;\n  mutate (mes = format(fecha, \"%m\")) |&gt;\n  ggplot(aes(x = mes, y = est)) +\n    geom_boxplot() +\n    labs(title = \"Boxplot de 'est' por Meses\",\n       x = \"Mes\",\n       y = \"Valor de est\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n(a) Boxplot básico de R\n\n\n\n\n\n\n\n\n\n\n\n(b) Boxplot utilizando ggplot()\n\n\n\n\n\n\n\nFigura 4.6: Ejemplos de boxplot",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#histogramas-y-diagramas-de-caja",
    "href": "040-exploracion.html#histogramas-y-diagramas-de-caja",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.8 Histogramas y diagramas de caja",
    "text": "4.8 Histogramas y diagramas de caja\nResulta muy útil comprender visualmente la relación entre el boxplot y el histograma para entender la distribución de los datos. En la gráfica siguiente se representan ambos simultáneamente\n\ndf_camembert |&gt;\nggplot(aes(x = est)) +\n  geom_histogram(fill = \"lightblue\", color = \"black\", bins = 20, alpha = 0.7) +\n  geom_boxplot(width = 2, fill = \"darkgrey\", alpha = 0.7, position = position_nudge(y = -2)) +\n  labs(title = \"Histograma y Boxplot\", y = \"Frecuencias\")\n\n\n\n\n\n\n\n\n\ndf_camembert |&gt;\nggplot(aes(x = log10(coliformes+1))) +\n  geom_histogram(fill = \"lightblue\", color = \"black\", bins = 20, alpha = 0.7) +\n  geom_boxplot(width = 4, fill = \"darkgrey\", alpha = 0.7, position = position_nudge(y = -4)) +\n  labs(title = \"Histograma y Boxplot\", y = \"Frecuencias\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#gráficos-de-dispersión",
    "href": "040-exploracion.html#gráficos-de-dispersión",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.9 Gráficos de dispersión",
    "text": "4.9 Gráficos de dispersión\nUn gráfico de dispersión, también conocido como diagrama de dispersión o scatter plot, es una representación gráfica que utiliza puntos para mostrar la relación entre dos variables numéricas. Cada punto en el gráfico representa una observación del conjunto de datos y se coloca en el plano cartesiano de acuerdo con sus valores en las dos variables que se están comparando.\nUn gráfico de dispersión se compone mediante puntos:\n\nCada punto en el gráfico representa una observación.\nLa posición del punto en el gráfico está determinada por los valores de las dos variables para esa observación.\n\nLos gráficos de dispersión son útiles para identificar varios aspectos de la relación entre las dos variables:\n\nSi los puntos tienden a agruparse a lo largo de una línea recta ascendente, esto indica una correlación positiva (a medida que una variable aumenta, la otra también lo hace).\nSi los puntos se agrupan a lo largo de una línea descendente, esto indica una correlación negativa (a medida que una variable aumenta, la otra disminuye).\nSi los puntos forman una curva en lugar de una línea recta, esto sugiere una relación no lineal entre las variables.\nLa dispersión de los puntos puede indicar la variabilidad de los datos. Puntos que están muy lejos del patrón general pueden ser valores atípicos.\n\nplot(df_camembert$est, df_camembert$mg)\n\ndf_camembert |&gt;\n  ggplot(aes(x=mg,y=est))+\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n(a) Gráfico de dispersion básico de R\n\n\n\n\n\n\n\n\n\n\n\n(b) Gráfico de dispersion utilizando ggplot()\n\n\n\n\n\n\n\nFigura 4.7: Ejemplos de gráfico de dispersión\n\n\n\nLos gráficos de dispersión son una herramienta esencial en el análisis de datos exploratorio, ya que permiten visualizar relaciones y patrones en los datos, identificar correlaciones y detectar posibles anomalías. Esta información es crucial para realizar análisis estadísticos más profundos y tomar decisiones basadas en datos.\nExcel no permite hacer gráficos de dispersión directamente, aunque sí podemos hacerlos de forma indirecta. Ver articulo blog",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "040-exploracion.html#gráficos-de-series-temporales",
    "href": "040-exploracion.html#gráficos-de-series-temporales",
    "title": "4  La exploración de los datos mediante gráficos.",
    "section": "4.10 Gráficos de series temporales",
    "text": "4.10 Gráficos de series temporales\nHasta ahora hemos utilizado gráficos y tablas que describen la estructura y forma de una variable, o las relaciones entre dos variables. Hay otros gráficos que tienen en cuenta la forma en la que esos datos cambian con el tiempo. En este caso, será necesario que hayamos recogido los intervalos de tiempo en los que se han producido nuestros valores en una variable de nuestra tabla.\nEn un gráfico de series temporales,\n\nel eje horizontal (X) representa el tiempo. Los puntos de tiempo pueden ser minutos, horas, días, meses, años, etc.\nel eje vertical (Y) representa los valores de la variable que se está estudiando. Estos valores pueden ser medidas como temperatura, ventas, precios, etc.\ncada valor individual corresponde a un punto\nlos valores se conectan mediante una línea que conecta los puntos de datos, mostrando cómo cambian los valores de la variable a lo largo del tiempo.\nnormalmente, en un gráfico de series temporales no suelen representarse los puntos individuales para facilitar la legibilidad del gráfico.\n\nEn nuestro conjunto de datos de fabricación de queso camembert, la primera columna de la tabla recoge la variable fecha, lo que nos permite ordenar nuestros valores en el tiempo.\nCuando representamos los valores en el tiempo, nunca usaremos el diagrama de barras, sino el gráfico de líneas.\nplot(df_camembert$fecha, df_camembert$est, type=\"l\")\n\ndf_camembert |&gt;\n  ggplot(aes(x=fecha, y=est))+\n  geom_line() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n(a) Gráfico de series temporales básico de R\n\n\n\n\n\n\n\n\n\n\n\n(b) Gráfico de series temporales utilizando ggplot()\n\n\n\n\n\n\n\nFigura 4.8: Ejemplos de gráfico de series temporales\n\n\n\nLos gráficos de series temporales son útiles para:\n\nIdentificar Tendencias:\n\nUna tendencia es una dirección general en la que los datos se mueven a lo largo del tiempo. Puede ser creciente, decreciente o constante.\n\nDetección de Estacionalidad:\n\nLa estacionalidad se refiere a patrones que se repiten en intervalos regulares de tiempo, como las ventas de productos estacionales.\n\nIdentificar Ciclos:\n\nLos ciclos son fluctuaciones que ocurren en intervalos no regulares y pueden deberse a factores económicos o de otra índole.\n\nDetección de Anomalías:\n\nLos picos y caídas repentinas pueden indicar eventos inusuales o errores en los datos.\n\n\nLos gráficos de series temporales son cruciales en diversas áreas:\n\nEconomía y Finanzas:\n\nSeguimiento de precios de acciones, tasas de interés y otros indicadores económicos.\n\nCiencia y Tecnología:\n\nMonitoreo de variables ambientales, datos meteorológicos y medidas científicas.\n\nNegocios:\n\nAnálisis de ventas, demanda de productos y desempeño empresarial a lo largo del tiempo.\n\n\nLos gráficos de series temporales proporcionan una visión clara y concisa de cómo cambian los datos a lo largo del tiempo. Esta visualización es fundamental para el análisis predictivo, la toma de decisiones y la identificación de patrones y anomalías en los datos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La exploración de los datos mediante gráficos.</span>"
    ]
  },
  {
    "objectID": "050-estad-simple.html",
    "href": "050-estad-simple.html",
    "title": "5  Medidas centrales y medidas de dispersión: la media y la varianza.",
    "section": "",
    "text": "5.1 La media aritmética: un ejemplo de cálculo.\nAl estudiar el diagrama de caja (boxplot) hemos visto que este gráfico se describe mediante los cinco números, que son:\nDe estos valores, el segundo cuartil, que se corresponde con la mitad de los valores, representa una estimación del centro de la distribución, y por eso lo llamamos mediana. La distancia entre el primer y tercer cuartil es lo que se conoce como rango intercuartil (se suele representar por sus siglas en inglés, IQR), y nos da una indicación de la dispersión: cuanto mayor mayor es la dispersión de nuestros valores, más alejados estarán del centro, y por lo tanto habrá mayor distancia entre el primer y el tercer cuartil.\nUna de las mayores ventajas de la mediana y del rango intercuartil es que son estadísticos robustos, es decir, tiene una alta robustez a los valores atípicos. Como en el cálculo del rango intercuartil no se tienen en cuenta los valores extremos, su valor variará muy poco si aparecen nuevas observaciones atípicas (outliers). Como sus valores no dependen de la distribución de los datos, a estos estadísticos se los conoce como no paramétricos.\nExisten otras estadísticos, llamados paramétricos, que, en determinadas condiciones, tienen ventajas frente a los no paramétricos. Los principales son la media aritmética, o simplemente, media, y la varianza.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Medidas centrales y medidas de dispersión: la media y la varianza.</span>"
    ]
  },
  {
    "objectID": "050-estad-simple.html#la-media-aritmética-un-ejemplo-de-cálculo.",
    "href": "050-estad-simple.html#la-media-aritmética-un-ejemplo-de-cálculo.",
    "title": "5  Medidas centrales y medidas de dispersión: la media y la varianza.",
    "section": "",
    "text": "5.1.1 Definición\nLa media aritmética de un conjunto de valores es el valor central que se obtiene al dividir la suma de todos los valores por la cantidad de valores. Es una medida de tendencia central que proporciona un punto de referencia para el conjunto de datos.\n\n\n5.1.2 Deducción de la Fórmula:\nSupongamos que tenemos un conjunto de \\(n\\) valores numéricos: \\(x_1, x_2, x_3, \\ldots, x_n\\).\n\nSuma de Todos los Valores: Primero, sumamos todos los valores del conjunto. Matemáticamente, esto se expresa como:\n\\[\nS = x_1 + x_2 + x_3 + \\cdots + x_n\n\\]\nCantidad de Valores: Luego, contamos cuántos valores hay en el conjunto. Este número es \\(n\\).\nDivisión de la Suma por la Cantidad de Valores: Finalmente, dividimos la suma total \\(S\\) por la cantidad de valores \\(n\\) para obtener la media aritmética:\n\\[\n\\text{Media Aritmética} = \\frac{S}{n}\n\\]\nExpresión General: Sustituyendo la suma \\(S\\) en la fórmula, tenemos:\n\\[\n\\text{Media Aritmética} = \\frac{x_1 + x_2 + x_3 + \\cdots + x_n}{n}\n\\]\n\n\n\n5.1.3 Ejemplo:\nSupongamos que tenemos los siguientes valores: \\(5, 7, 9\\).\n\nSuma de los Valores: \\[\nS = 5 + 7 + 9 = 21\n\\]\nCantidad de Valores: \\[\nn = 3\n\\]\nCálculo de la Media Aritmética: \\[\n\\text{Media Aritmética} = \\frac{21}{3} = 7\n\\]\n\nEntonces, la media aritmética de los valores \\(5, 7, 9\\) es \\(7\\).\nLa media de una muestra se representa habitualmente mediante el símbolo\n\\[\\bar{x}\\] y, de una manera más formal, su valor se obtiene mediante la fórmula siguiente:\n\\[{\\bar{x}={\\frac {1}{n}}\\sum _{i=1}^{n}x_{i}}\\] El signo \\(\\sum\\) se conoce como sumatorio, e indica que ese término consiste en la suma de los \\(x\\) valores desde el primero hasta el valor \\(n\\). Expresado mediante una formulación matemática,\n\\[{\\bar{x}={\\frac {1}{n}}\\sum _{i=1}^{n}x_{i}={\\frac {x_{1}+x_{2}+\\cdots +x_{n}}{n}}}\\] lo quiere quiere decir: “la suma de todos los valores observados dividido entre el número de estos valores”.\nLa media es lo que conocemos como un valor central, ya que representa el centro de nuestro conjunto de números. Como es el centro de nuestro conjunto de datos, la suma de las distancias de todos los valores a este valor central es \\(cero\\). Más adelante veremos la importancia de este hecho, al hablar de la dispersión y las formas de cálculo de la misma. Como hemos visto, la media de una muestra se representa como \\(\\bar{x}\\), mientras que la media de una población se representa con la letra griega mu: \\(\\mu\\). En ambos casos, el cálculo se realiza de forma idéntica.\nVolvamos a nuestro ejemplo de la altura de un grupo de alumnos, para realizar los cálculos según el modelo que hemos descrito. En nuestro caso, la altura media de nuestros alumnos (la media de nuestro conjunto de números) se calcula como:\n\\[\n\\bar{x} = \\frac{153+135+140+140+175+138+145+154+152+159+154}{11} = 149,54\n\\] Utilicemos una hoja de cálculo para guardar nuestros valores.\n\nLa fórmula para obtener la media en la hoja de cálculo, por ejemplo en la versión en español de Microsoft Excel, es =PROMEDIO(...), donde los puntos suspensivos deben sustituirse por el rango a calcular. En nuestro ejemplo, introduciríamos la fórmula en la celda B13como =PROMEDIO(B2..B12) (Para más detalles, verificar la hoja Excel adjunta).\nPara representar más cómodamente nuestros valores, dibujamos un punto a la altura de cada alumno,\n\ny eliminamos del gráfico los dibujos de nuestros alumnos; así hemos convertido nuestro dibujo en un diagrama de puntos:\n\nPara representar la media, aunque la media es un valor único, necesitamos añadir una columna a la derecha de nuestros datos, que rotulamos en la fila 1, celda C como altura media, e introducimos en cada una de las celdas desde C2hasta C12la fórmula del promedio, con el valor de nuestro rango de datos (Verificar hoja de cálculo). A continuación, designamos nuestro rango de datos para hacer un gráfico de puntos, y hacemos un zoom en los valores de manera que el eje Y se escale mejor entre los valores mínimo y máximo. Por último, hacemos unos ajustes en el formato para dibujar las líneas verticales que nos representan la distancia de cada valor a la media.\n\nSi verificamos el eje \\(Y\\) , veremos que en este gráfico hemos ajustado la escala respecto al gráfico anterior, situando el mínimo en \\(130\\). Esto permite visualizar las diferencias con mucha más claridad. Hemos representado la media \\(\\bar{x}\\) como una línea, y hemos dibujado unas líneas que unen cada valor individual con la media, que se sitúa en el valor \\(149,55\\), tal como calculamos más arriba.\nHemos representado la media como una serie de puntos unidos por una línea amarilla. Representamos en azul nuestros valores, uniendo cada valor con la línea media mediante una línea de puntos vertical. A partir de ahora, por conveniencia, eliminaremos los puntos en la linea media, dejando sólo la línea.\n\n\n\nHoja de cálculo con los valores y el gráfico de puntos\n\n\nEsta línea azul de puntos representa la distancia de cada valor a la media. Usaremos esta distancia para calcular una distancia media, que será una medida de la dispersión de nuestros valores.\nHemos visto que para describir un conjunto de números, en nuestro ejemplo, las medidas de la altura de un grupo de estudiantes, existe un valor, la media de este conjunto, que nos describe el centro de los valores. En nuestro ejemplo, si nuestro grupo tuviese un solo niño, éste tendría \\(149,55{\\ }cm\\) de altura.\n¿Es suficiente con este valor para describir el conjunto de valores? Vamos a ver que no: diferentes conjuntos de valores pueden proporcionar el mismo valor medio, y sin embargo los grupos pueden ser muy diferentes.\nVeamos un caso extremo. Comparemos dos grupos, uno formado por individuos iguales y otro formado por diez individuos iguales y uno distinto. Para ello usaremos nuestra hoja de cálculo:\n\n\n\n\nDos grupos de valores con la misma media\n\n¿Podemos describir adecuadamente los valores de la altura de cada uno de los grupos utilizando el valor medio? Parece evidente que no, ya que a partir de diferentes valores de altura estamos obteniendo el mismo valor medio. Sin embargo, uno de los grupos es más alto que el otro, si no fuera por un sólo individuo que aparentemente distorsiona el cálculo. Podríamos incluir nuestro grupo original, y veremos que los tres grupos son diferentes, aunque su valor medio es idéntico.\n\n\n\n\nTres grupos de valores con la misma media\n\nSi nos ayudamos de un gráfico equivalente al que hemos utilizado antes, vemos estas diferencias con claridad:\n\n\n\nGráfico de tres grupos de valores\n\n\nAunque el valor medio de estos tres grupos de datos es idéntico, parece claro que los tres grupos son muy distintos en su composición, y por lo tanto la media no es suficiente para describir con suficiente precisión cada uno de los grupos. Necesitamos un valor adicional, que nos indique de qué forma los valores se alejan del valor medio. Para ello, vamos a introducir un concepto nuevo: la medida de la dispersión.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Medidas centrales y medidas de dispersión: la media y la varianza.</span>"
    ]
  },
  {
    "objectID": "050-estad-simple.html#las-medidas-de-dispersión-la-varianza-y-la-desviación-típica",
    "href": "050-estad-simple.html#las-medidas-de-dispersión-la-varianza-y-la-desviación-típica",
    "title": "5  Medidas centrales y medidas de dispersión: la media y la varianza.",
    "section": "5.2 Las medidas de dispersión: la varianza y la desviación típica",
    "text": "5.2 Las medidas de dispersión: la varianza y la desviación típica\nComo hemos visto en el apartado anterior, diferentes conjuntos de datos pueden tener el mismo valor medio y sin embargo ser muy diferentes. En la última gráfica que hemos visto, el primer grupo se caracteriza por tener todos sus valores idénticos; el segundo tiene todos sus valores idénticos menos uno, que está muy apartado del resto, y el tercero tiene todos sus valores diferentes.\nAhora que conocemos cómo calcular un valor resumen de un conjunto de datos, podríamos utilizar una medida semejante para describir de qué forma en cada caso los valores se separan de la media. Podríamos utilizar una distancia media: calculamos las diferencias entre cada valor y la media, y hacemos su promedio: esto debería darnos una indicación de la magnitud de la separación de los valores en cada uno de los tres grupos.\nUsemos la hoja de cálculo para ello:\n\n\n\nTres grupos de valores en la hoja de cálculo\n\n\nAlgo parece que no está funcionando aquí: el promedio de las diferencias es cero en los tres casos; no podemos usar este cálculo para calcular la dispersión. Pero esto es esperable: ya que la media es un valor central, como hemos visto antes, la suma de las diferencias de todos los valores respecto de su media debe ser forzosamente cero, y esto es lo que estamos obteniendo.\nPara encontrar una solución, vamos a recurrir al viejo teorema de Pitágoras, que si recuerdas, nos dice que, en un triángulo rectángulo, el cuadrado de la hipotenusa es igual a la suma de los cuadrados de los catetos (una explicación gráfica muy divertida en el anexo …): \\[\nh^2= a^2+b^2\n\\] Esta fórmula es la base del cálculo de la distancia entre dos puntos:\n\n\n\n\nDistancia entre dos puntos\n\n\\[\nd(A,B)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\n\\] Podemos adaptar esta fórmula al cálculo de nuestra distancia media. Como estamos calculando la distancia en una dimensión, sólo necesitamos la coordenada \\(X\\). Si tenemos en cuenta un solo punto, esta distancia \\(d\\) sería: \\[\n(d{\\ }del{\\ }valor{\\ }1{\\ }a{\\ }la{\\ }media)^2=(x_1-\\bar{x})^2\n\\] ¡El hecho de elevar al cuadrado las diferencias nos da la solución! Las diferencias negativas ya no son un problema porque sabemos que al elevar un numero negativo al cuadrado, el resultado es positivo; de esta manera conseguimos que las diferencias no se anulen. Ahora sí podemos calcular una distancia media \\(\\bar{d}\\) entre el conjunto de puntos y su media, calculando el promedio de las diferencias elevadas al cuadrado: \\[\n(\\bar{d}{\\ }de{\\ }los{\\ }n{\\ }valores{\\ }a{\\ }la{\\ }media)^2=\\frac{(x_1-\\bar{x})^2 + (x_2-\\bar{x})^2+\\cdots+(x_n-\\bar{x})^2}{n}\n\\]\ny utilizando la notación que hemos aprendido antes,\n\\[\n(\\bar{d}{\\ }de{\\ }los{\\ }n{\\ }valores{\\ }a{\\ }la{\\ }media)^2={\\frac {1}{n}}\\sum _{i=1}^{n}(x_{i}-\\bar{x})^2\n\\]\nAl igual que en el cálculo de la distancia entre dos puntos, sólo tenemos que extraer la raíz cuadrada de este valor para obtener la distancia media, que es el parámetro que estábamos buscando.\nLa distancia media \\[(\\bar{d}{\\ }de{\\ }los{\\ }n{\\ }valores{\\ }a{\\ }la{\\ }media)^2\\] se conoce en estadística como varianza, y su raíz cuadrada es lo que se conoce como desviación típica. La varianza de una población se representa en estadística con el signo de la letra griega sigma minúscula elevada al cuadrado, \\(\\sigma^2\\), y la desviación típica, mediante la letra \\(\\sigma\\). En el caso de una muestra, la varianza se representa como \\(s_x^2\\), y la desviación típica, como \\(s_x\\).\nEs importante resaltar que la desviación típica es una medida de la distancia media de los valores de una población a su media, y por lo tanto tiene dimensión, la misma que las medidas originales. La varianza, al estar elevada al cuadrado, no tiene una dimensión, o, mejor dicho, tiene la de la medida al cuadrado.\nCon estos nuevos hallazgos, recalculamos nuestra hoja de cálculo:\n\n\n\nTres grupos de valores en la hoja de cálculo, con la misma media y distinta desviación típica\n\n\nVamos a analizar con detalle esta tabla.\nEn la columna J tenemos nuestra población original de 11 alumnos, con las alturas que hemos medido. En la columna B hemos supuesto que todos los alumnos fuesen iguales, con la misma altura del valor medio de los datos originales. En la columna F hemos simulado otro grupo, con todos los valores iguales excepto uno, y con la misma media que los otros dos grupos.\nA la derecha de cada columna de medias, tenemos la columna de diferencias (columnas D, H y L), y en la fila 13, nuestro primer intento de calcular una dispersión media; intento fallido, puesto que obteníamos el valor \\(0\\) para los tres grupos.\nEn la siguiente columna a la derecha, para los tres grupos (columnas E, Iy M), hemos elevado al cuadrado la distancia de cada valor a la media, siguiendo los hallazgos que nos ha proporcionado el teorema de Pitágoras y la fórmula de la distancia entre dos puntos. En la fila 13 de estas columnas, calculamos el promedio de la distancia a la media al cuadrado: esta vez el resultado ya no es cero, sino que obtenemos el valor de la varianza, de acuerdo con la fórmula que hemos deducido más arriba. En la fila 14 (columnas B, F y J)utilizamos la fórmula de la hoja de cálculo para la varianza poblacional (más detalles posteriormente), y vemos que coincide exactamente con el promedio de las diferencias al cuadrado, tal como debe ser, ya que en eso consiste la fórmula que hemos deducido.\nPor último, en la fila 15calculamos la desviación típica de ambas formas, con la fórmula de la hoja de cálculo para la desviación típica poblacional (columnas B, Fy J), que Excel llama desviación estándar, y como la raíz cuadrada del promedio calculado antes (columnas E, Iy M). De nuevo, ambos valores coinciden exactamente, como esperamos.\n\n\n\nGráfico con tres conjuntos de datos con la misma media y diferente desviación típica\n\n\nAhora sí tenemos una forma más completa de describir nuestro conjunto de valores. Aunque el valor medio es el mismo en los tres casos, la dispersión de los valores es muy distinta.\n¿Son suficientes estos dos parámetros que hemos calculado para describir un conjunto de datos? La respuesta a esta pregunta es sí y no. La explicación es que, más allá de los valores numéricos que hemos obtenido, la visualización gráfica de los valores nos debe hacer reflexionar.\nEn el primer grupo, todos los valores son iguales a la media. La variación es cero. Son valores que hemos simulado en nuestra hoja de cálculo, pero difícilmente en el mundo real encontraremos una población en la que todos sus valores, en este caso, la altura de un grupo de alumnos, sean idénticos.\nEn el segundo grupo, todos los valores son idénticos, salvo uno, que se distancia mucho. ¿Debemos aceptar esto como bueno? En realidad, ¿es cierto que el valor medio de este grupo sea el mismo que el del primero? Para responder a esta pregunta debemos recurrir a nuestra experiencia, la estadística no nos da fórmulas mágicas. Pero, con un poco de sentido común, parece que el caso extremo que aparece en este grupo no es coherente con el resto de valores. Es lo que se llama un valor anormal o extraño (en inglés, outlier), y debe hacernos reflexionar sobre si el valor es correcto y realmente pertenece a esta población, o es un error de medida. O, simplemente, un valor que corresponde a otro grupo y que por error hemos situado en éste. La decisión de eliminar o no un valor anormal es una de las decisiones más complejas en estadística, que pueden tener una influencia enorme en la interpretación de los datos, y por lo tanto, hay que hacer con sumo cuidado. En este caso, extremo y artificial, el valor anormal debería ser eliminado, ya que, en realidad, todos los valores restantes son idénticos y más bajos que los del grupo 1. No tiene sentido lógico decir que sus medias son idénticas.\nEn el tercer grupo todos los valores son diferentes, y no podemos decir nada especial sobre sus valores individuales. Hay un valor que se destaca del resto, pero ¿podemos afirmar que es anormal? Seguramente, no con seguridad. De nuevo la experiencia debe indicarnos cómo proceder, aunque en este caso no tendría sentido eliminar este valor. En la situación real, todos conocemos a niños que han pegado el estirón antes que sus compañeros, y en algunos casos, pueden llegar a ser mucho más altos (o más bajos, si han tenido un retraso en este estirón) La experiencia nos dice que no es seguro que este valor sea realmente anormal, y por lo tanto, deberíamos conservarlo.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Medidas centrales y medidas de dispersión: la media y la varianza.</span>"
    ]
  },
  {
    "objectID": "050-estad-simple.html#las-limitaciones-de-la-media-y-la-desviación-típica",
    "href": "050-estad-simple.html#las-limitaciones-de-la-media-y-la-desviación-típica",
    "title": "5  Medidas centrales y medidas de dispersión: la media y la varianza.",
    "section": "5.3 Las limitaciones de la media y la desviación típica",
    "text": "5.3 Las limitaciones de la media y la desviación típica\nEn ocasiones nos enfrentamos a conjuntos de datos con valores de media y desviación típica idénticos o muy parecidos, pero que en realidad son muy diferentes. Veamos un ejemplo, semejante a los que hemos visto hasta ahora.\n\n\n\n\nHoja de cálculo con dos conjuntos de datos diferentes, con la misma media y desviación típica\n\n(cambiar a caso 3)\n\n\n\nDiagrama de puntos de las alturas de los alumnos, con indicación del valor medio\n\n\n\n\n\nDiagrama de puntos indicando la variabilidad\n\n\nEn este caso, vemos que tanto la media como la desviación típica son idénticos, y sin embargo los datos son muy diferentes, tal como nos muestra el gráfico de dispersión que hemos estado utilizando:\n\n\n\nGráfico con dos conjuntos de datos diferentes, con la misma media y desviación típica\n\n\nLa existencia de valores anormales o extremos muestra una de las debilidades de la media y la desviación típicas como descriptores de una población: ambos parámetros son muy sensibles a los casos extremos. En realidad, sólo deberíamos utilizar la media y la desviación típica para describir un conjunto de datos cuando estamos seguros de que la distribución de estos datos tienen una forma determinada, la de la campana de Gauss. En otros casos, la mediana y el rango intercuartil son estadísticos más robustos, y por lo tanto más seguros.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Medidas centrales y medidas de dispersión: la media y la varianza.</span>"
    ]
  },
  {
    "objectID": "050-estad-simple.html#resumen",
    "href": "050-estad-simple.html#resumen",
    "title": "5  Medidas centrales y medidas de dispersión: la media y la varianza.",
    "section": "5.4 Resumen",
    "text": "5.4 Resumen\nLas medidas paramétricas, como la media y la varianza, y las no paramétricas, como la mediana y el rango intercuartil, tienen diferentes ventajas e inconvenientes según el contexto y los datos con los que se trabaja.\n\n5.4.1 Ventajas e inconvenientes de las medidas paramétricas\n\n5.4.1.1 Ventajas\n\nPrecisión y Sensibilidad: La media y la varianza son muy precisas y sensibles a todos los valores del conjunto de datos.\nPropiedades Matemáticas: La media y la varianza tienen propiedades matemáticas deseables, como la facilidad para realizar operaciones algebraicas.\nDistribución Normal: Son especialmente útiles si los datos siguen una distribución normal, ya que permiten aprovechar las propiedades de esta distribución.\n\n\n\n5.4.1.2 Inconvenientes\n\nSensibilidad a Valores Atípicos: La media y la varianza pueden ser distorsionadas significativamente por valores atípicos.\nRequieren Suposiciones: Su uso eficaz a menudo requiere que los datos sigan ciertas suposiciones, como la normalidad y la homogeneidad de la varianza.\n\n\n\n\n5.4.2 Ventajas e inconvenientes de las medidas no paramétricas\n\n5.4.2.1 Ventajas\n\nRobustez: La mediana y el rango intercuartil son menos sensibles a valores atípicos y distribuciones asimétricas.\nFlexibilidad: No requieren suposiciones fuertes sobre la distribución de los datos, lo que las hace útiles para una amplia variedad de distribuciones.\nResumir Datos: Son excelentes para resumir datos en situaciones en las que los valores extremos podrían distorsionar la interpretación.\n\n\n\n5.4.2.2 Inconvenientes\n\nMenor Sensibilidad: La mediana y el rango intercuartil no utilizan toda la información de los datos y pueden ser menos sensibles a cambios en los datos.\nMenor Precisión en Ciertos Contextos: En situaciones donde los datos siguen una distribución normal, las medidas no paramétricas pueden ser menos precisas.\n\nLas medidas paramétricas son útiles para datos que siguen suposiciones específicas, como la normalidad, y son precisas y sensibles, pero pueden ser distorsionadas por valores atípicos. Las medidas no paramétricas son robustas y flexibles, ideales para distribuciones no normales y resistentes a valores atípicos, aunque pueden perder sensibilidad y precisión en ciertos contextos.\nModelo: práctica de puntos con un dado, dos dados, tres dados, etc hasta 30\nsuma &lt;- rowSums(replicate(30, sample(6, 10^6, replace=T))) length(suma) hist(suma)\nFinancial Times Visual Vocabulary: Power BI Edition – Some Random Thoughts (sqljason.com)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Medidas centrales y medidas de dispersión: la media y la varianza.</span>"
    ]
  },
  {
    "objectID": "050-estad-simple.html#la-media-aritmética-como-centro-de-gravedad-de-un-grupo-de-datos",
    "href": "050-estad-simple.html#la-media-aritmética-como-centro-de-gravedad-de-un-grupo-de-datos",
    "title": "5  Medidas centrales y medidas de dispersión: la media y la varianza.",
    "section": "5.5 La media aritmética como centro de gravedad de un grupo de datos",
    "text": "5.5 La media aritmética como centro de gravedad de un grupo de datos\nPara ver cómo la media aritmética equivale al punto de equilibrio o centro de gravedad de un grupo de datos, imaginaremos que tenemos un conjunto de datos cuyos valores se distribuyen en un eje longitudinal X. Podemos hacer equivalentes estos valores a un conjunto de pesos que se distribuyen a lo largo de una barra, y vamos a suponer que existe un punto a una distancia \\(d_i\\) del origen de la barra en el cual dicha barra está en equilibrio. Para encontrar ese valor, empezaremos considerando el principio o ley de la palanca.\nEl Principio de la Palanca o la Ley de la Palanca fue formulada por el científico y matemático griego Arquímedes. Este principio dice que, en equilibrio, el producto de la fuerza aplicada (potencia) por su distancia al punto de apoyo (brazo de la potencia) es igual al producto de la resistencia por su distancia al punto de apoyo (brazo de la resistencia). Matemáticamente, se expresa como: \\[\nP \\cdot d_p = R \\cdot d_r\n\\]\nDonde: - \\(P\\) es la potencia o fuerza aplicada. - \\(d_p\\) es la distancia desde el punto de apoyo hasta el punto donde se aplica la potencia. - \\(R\\) es la resistencia o carga. - \\(d_r\\) es la distancia desde el punto de apoyo hasta el punto donde se aplica la resistencia.\n\n5.5.1 Ejemplo\nSi tienes una palanca con una longitud de 5 metros y aplicas una fuerza de 10 Newtons a 1 metro del punto de apoyo, para mantener el equilibrio, la fuerza de resistencia en el otro extremo a 4 metros del punto de apoyo debería ser: \\[\nP \\cdot d_p = R \\cdot d_r\n\\] \\[\n10 \\, \\text{N} \\cdot 1 \\, \\text{m} = R \\cdot 4 \\, \\text{m}\n\\] \\[\nR = \\frac{10 \\cdot 1}{4} = 2,5 \\text{N}\n\\]\nAhora vamos a considerar el punto de equilibrio de una barra de la que se cuelgan diferentes pesos a diferente distancias de su origen.\nCalcular el punto de equilibrio de una barra de la que se cuelgan diferentes pesos a diferentes distancias de su origen es un problema clásico de física que se puede resolver usando el principio de momentos.\n\n\n5.5.2 Paso a Paso\n\nIdentificar las fuerzas: Supongamos que tienes varios pesos \\(W_1, W_2, W_3, \\ldots, W_n\\) colgados a distancias \\(d_1, d_2, d_3, \\ldots, d_n\\) del origen (punto de apoyo).\nCalcular los momentos: El momento (\\(M\\)) de un peso alrededor del punto de apoyo se calcula como el producto de la fuerza (peso) y la distancia al punto de apoyo: \\[\nM_i = W_i \\times d_i\n\\]\nSumar los momentos: Calcula la suma de todos los momentos: \\[\nM_{\\text{total}} = W_1 \\times d_1 + W_2 \\times d_2 + W_3 \\times d_3 + \\ldots + W_n \\times d_n\n\\]\nCalcular el peso total: Suma todos los pesos: \\[\nW_{\\text{total}} = W_1 + W_2 + W_3 + \\ldots + W_n\n\\]\nDeterminar el punto de equilibrio (\\(x\\)): El punto de equilibrio se encuentra dividiendo la suma de los momentos por el peso total: \\[\nx = \\frac{\\sum (W_i \\times d_i)}{\\sum W_i}\n\\]\n\n\n\n5.5.3 Ejemplo Práctico\nSupongamos que tenemos tres pesos de 4, 9 y 1 kg, situados, respectivamente, a 2, 1 y 3 m respectivamente del origen de la barra.\n\n\\(W_1 = 4 \\, \\text{kg}\\) a \\(d_1 = 2 \\, \\text{m}\\)\n\\(W_2 = 9 \\, \\text{kg}\\) a \\(d_2 = 1 \\, \\text{m}\\)\n\\(W_3 = 1 \\, \\text{kg}\\) a \\(d_3 = 3 \\, \\text{m}\\)\n\n\nCalcular los momentos: \\[\nM_1 = 4 \\times 2 = 8 \\, \\text{kg·m}\n\\] \\[\nM_2 = 9 \\times 1 = 9 \\, \\text{kg·m}\n\\] \\[\nM_3 = 1 \\times 3 = 3 \\, \\text{kg·m}\n\\]\nSumar los momentos: \\[\nM_{\\text{total}} = 8 + 9 + 3 = 20 \\, \\text{kg·m}\n\\]\nCalcular el peso total: \\[\nW_{\\text{total}} = 4 + 9 + 1 = 14 \\, \\text{kg}\n\\]\nDeterminar el punto de equilibrio:\n\\[\nx = \\frac{20}{14} \\approx 1.43 \\, \\text{m}\n\\]\n\nEl punto de equilibrio se encuentra a aproximadamente 1.43 metros del origen.\n\n\n5.5.4 Media Ponderada\nEn muchas situaciones, el centro de gravedad de un sistema de masas puede interpretarse como una media ponderada de las posiciones de las masas.\n\n5.5.4.1 Media Aritmética\nPara un conjunto de números \\(x_1, x_2, \\ldots, x_n\\), la media aritmética es: \\[\n\\text{Media} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\n\\]\n\n\n5.5.4.2 Media Ponderada\nPara un conjunto de valores \\(x_1, x_2, \\ldots, x_n\\) con pesos asociados \\(w_1, w_2, \\ldots, w_n\\), la media ponderada es: \\[\n\\text{Media ponderada} = \\frac{w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n}{w_1 + w_2 + \\cdots + w_n}\n\\]\n\n\n\n5.5.5 Centro de Gravedad como Media Ponderada\nCuando calculamos el centro de gravedad (\\(x_{\\text{cg}}\\)) de un sistema de masas, estamos esencialmente calculando una media ponderada de las posiciones (\\(x_i\\)) de esas masas (\\(m_i\\)):\n\\[\nx_{\\text{cg}} = \\frac{\\sum (m_i \\cdot x_i)}{\\sum m_i}\n\\]\nAquí, las posiciones \\(x_i\\) son ponderadas por las masas \\(m_i\\).\n\n\n5.5.6 Ejemplo Numérico\nEn nuestro ejemplo anterior,\n\nMasa 1: \\(m_1 = 4 \\, \\text{kg}\\) en posición \\(x_1 = 2 \\, \\text{m}\\)\nMasa 2: \\(m_2 = 9 \\, \\text{kg}\\) en posición \\(x_2 = 1 \\, \\text{m}\\)\nMasa 3: \\(m_3 = 1 \\, \\text{kg}\\) en posición \\(x_3 = 3 \\, \\text{m}\\)\n\nLa media aritmética de las posiciones sería: \\[\n\\text{Media} = \\frac{2 + 1 + 3}{3} = 2 \\, \\text{m}\n\\]\nEl punto de equlibrio de la barra, o centro de gravedad, calculado como media ponderada, sería:\n\\[\nx_{\\text{cg}} = \\frac{(4 \\cdot 2) + (9 \\cdot 1) + (1 \\cdot 3)}{4 + 9 + 1} = \\frac{8 + 9 + 3}{14} = \\frac{20}{14} \\approx 1,43 \\, \\text{m}\n\\] que es el mismo resultado que obteníamos formulando el cálculo de los momentos; la fórmula resulta ser idéntica.\n\n\n5.5.7 Media Aritmética y Centro de Gravedad con Masas Idénticas\nEn los ejemplos anteriores, calculábamos el punto de equilibrio para diferentes pesos colocados a lo largo de una barra. Si en vez de eso suponemos que la distancia al origen de la barra equivale a nuestro eje \\(X\\), que recoge los valores de los que queremos calcular nuestra media aritmética, podemos eliminar el efecto de la masa suponiendo que todas las masas son iguales.\nSi las masas de los diferentes objetos son idénticas, podemos decir que la media aritmética de las posiciones coincide con el centro de gravedad. Esto se debe a que, en este caso, cada masa tiene el mismo peso o influencia en el cálculo del centro de gravedad. Esta es la explicación detallada:\n\n5.5.7.1 Suposición\nCada objeto tiene la misma masa \\(m\\).\n\n\n5.5.7.2 Media Aritmética\nPara un conjunto de posiciones \\(x_1, x_2, \\ldots, x_n\\), la media aritmética es: \\[\n\\text{Media} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\n\\]\n\n\n5.5.7.3 Centro de Gravedad\nEl centro de gravedad (\\(x_{\\text{cg}}\\)) para un conjunto de masas idénticas en posiciones \\(x_1, x_2, \\ldots, x_n\\) es: \\[\nx_{\\text{cg}} = \\frac{\\sum (m \\cdot x_i)}{\\sum m}\n\\]\nDado que las masas \\(m\\) son idénticas, el numerador se convierte en: \\[\n\\sum (m \\cdot x_i) = m \\cdot (x_1 + x_2 + \\cdots + x_n)\n\\]\nY el denominador se convierte en: \\[\n\\sum m = n \\cdot m\n\\]\nAl sustituir estos en la fórmula del centro de gravedad, obtenemos: \\[\nx_{\\text{cg}} = \\frac{m \\cdot (x_1 + x_2 + \\cdots + x_n)}{n \\cdot m}\n\\]\nAl simplificar, los términos \\(m\\) se cancelan, y nos queda: \\[\nx_{\\text{cg}} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\n\\] que es exactamente la fórmula de la media aritmética.\nSi repetimos nuestro ejemplo anterior, suponiendo en este caso masas idénticas\n\nMasa 1: \\(m_1 = 1 \\, \\text{kg}\\) en posición \\(x_1 = 2 \\, \\text{m}\\)\nMasa 2: \\(m_2 = 1 \\, \\text{kg}\\) en posición \\(x_2 = 1 \\, \\text{m}\\)\nMasa 3: \\(m_3 = 1 \\, \\text{kg}\\) en posición \\(x_3 = 3 \\, \\text{m}\\)\n\nLa media aritmética de las posiciones sería: \\[\n\\text{Media} = \\frac{2 + 1 + 3}{3} = 2 \\, \\text{cm}\n\\]\nEl punto de equlibrio de la barra, o centro de gravedad, calculado como media ponderada, sería:\n\\[\nx_{\\text{cg}} = \\frac{(1 \\cdot 2) + (1 \\cdot 1) + (1 \\cdot 3)}{1 + 1 + 1} = \\frac{2 + 1 + 3}{3} = \\frac{6}{3} = 2 \\, \\text{m}\n\\] que es el mismo resultado que obteníamos con la fórmula de la media aritmética de las distancias.\n\n\n\n5.5.8 Conclusión\nCuando las masas son idénticas, la media aritmética de las posiciones coincide con el centro de gravedad. Esto nos permite afirmar que en el caso de una dimensión (por ejemplo, el peso) la media aritmética de un conjunto de valores coincide con el centro de gravedad o punto de equilibrio de ese conjunto de valores.Este es un resultado interesante que muestra la conexión entre conceptos estadísticos y físicos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Medidas centrales y medidas de dispersión: la media y la varianza.</span>"
    ]
  },
  {
    "objectID": "050-estad-simple.html#importancia-del-concepto-de-la-media-como-centro-de-gravedad-o-punto-de-equilibrio-de-un-conjunto-de-datos",
    "href": "050-estad-simple.html#importancia-del-concepto-de-la-media-como-centro-de-gravedad-o-punto-de-equilibrio-de-un-conjunto-de-datos",
    "title": "5  Medidas centrales y medidas de dispersión: la media y la varianza.",
    "section": "5.6 Importancia del concepto de la media como centro de gravedad o punto de equilibrio de un conjunto de datos",
    "text": "5.6 Importancia del concepto de la media como centro de gravedad o punto de equilibrio de un conjunto de datos\nEfecto de los outliers: desequilibrio, desplazamiento de la media, incremento de la varianza (gan diferencia), mientras que la mediana y el rango intercuartil no se ven afectados",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Medidas centrales y medidas de dispersión: la media y la varianza.</span>"
    ]
  },
  {
    "objectID": "055-forma-de-los-datos.html",
    "href": "055-forma-de-los-datos.html",
    "title": "6  La forma de los datos",
    "section": "",
    "text": "6.0.1 Introducción al Estudio de la Forma de los Datos\nEl estudio de la forma de los datos es fundamental en el análisis de datos y la estadística. Nos permite entender la distribución, tendencias, patrones y anomalías presentes en los datos, lo cual es esencial para tomar decisiones informadas y realizar análisis precisos. En esta introducción, exploraremos varios métodos y herramientas para examinar la forma de los datos, utilizando ejemplos en R, un lenguaje de programación muy utilizado en análisis de datos.\n\n\n6.0.2 Análisis Descriptivo\nEl primer paso para entender la forma de los datos es realizar un análisis descriptivo. Este análisis incluye el cálculo de medidas como la media, mediana, moda, desviación estándar y percentiles, que resumen las características principales de los datos.\n\n# Cargar librería\nlibrary(dplyr)\n\n# Crear un conjunto de datos\ndatos &lt;- c(23, 19, 23, 21, 22, 21, 20, 23, 22, 19)\n\n# Calcular medidas descriptivas\nmedia &lt;- mean(datos)\nmediana &lt;- median(datos)\nmoda &lt;- as.numeric(names(sort(table(datos), decreasing=TRUE)[1]))\ndesviacion_estandar &lt;- sd(datos)\n\n# Mostrar resultados\ncat(\"Media:\", media, \"\\n\")\n\nMedia: 21.3 \n\ncat(\"Mediana:\", mediana, \"\\n\")\n\nMediana: 21.5 \n\ncat(\"Moda:\", moda, \"\\n\")\n\nModa: 23 \n\ncat(\"Desviación Estándar:\", desviacion_estandar, \"\\n\")\n\nDesviación Estándar: 1.567021 \n\n\n\n\n6.0.3 Visualización de Datos\nLa visualización de datos es una herramienta poderosa para estudiar la forma de los datos. Gráficos como histogramas, diagramas de cajas y gráficos de dispersión permiten visualizar la distribución y las relaciones en los datos.\n\n# Cargar librería\nlibrary(ggplot2)\n\n# Crear un histograma\nggplot(data.frame(datos), aes(x = datos)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", alpha = 0.7, color = \"black\") +\n  labs(title = \"Histograma de Datos\", x = \"Valores\", y = \"Frecuencia\")\n\n\n\n\n\n\n\n# Crear un diagrama de cajas\nggplot(data.frame(datos), aes(y = datos)) +\n  geom_boxplot(fill = \"cyan\", color = \"black\") +\n  labs(title = \"Diagrama de Cajas de Datos\", y = \"Valores\")\n\n\n\n\n\n\n\n\n\n\n6.0.4 Análisis Exploratorio de Datos (EDA)\nEl Análisis Exploratorio de Datos (EDA) implica técnicas gráficas y cuantitativas para descubrir patrones, detectar anomalías y verificar hipótesis. EDA es una fase preliminar clave en el análisis de datos.\n\n# Crear un conjunto de datos de ejemplo\nset.seed(123)\ndatos_eda &lt;- data.frame(\n  x = rnorm(100),\n  y = rnorm(100)\n)\n\n# Crear un gráfico de dispersión\nggplot(datos_eda, aes(x = x, y = y)) +\n  geom_point(color = \"blue\") +\n  labs(title = \"Gráfico de Dispersión\", x = \"Variable X\", y = \"Variable Y\")\n\n\n\n\n\n\n\n\n\n\n6.0.5 Pruebas Estadísticas\nLas pruebas estadísticas, como la prueba de normalidad (Kolmogorov-Smirnov, Shapiro-Wilk), ayudan a determinar si los datos siguen una distribución específica.\n\n# Prueba de normalidad Shapiro-Wilk\nshapiro_test &lt;- shapiro.test(datos)\n\n# Mostrar resultado\ncat(\"Prueba de Shapiro-Wilk: p-value =\", shapiro_test$p.value, \"\\n\")\n\nPrueba de Shapiro-Wilk: p-value = 0.1400044 \n\n\n\n\n6.0.6 Importancia del Estudio de la Forma de los Datos\nComprender la forma de los datos es crucial para identificar patrones, detectar anomalías, seleccionar modelos apropiados y visualizar datos de manera efectiva. Un buen entendimiento de la forma de los datos permite tomar decisiones más informadas y basadas en evidencia, mejorando la calidad del análisis y la interpretación de los resultados.\nEn resumen, el estudio de la forma de los datos a través del análisis descriptivo, visualización de datos, EDA y pruebas estadísticas, nos proporciona una comprensión profunda de los datos y nos guía en el proceso de análisis. Utilizar herramientas como R facilita este estudio y nos permite trabajar con datos de manera más eficiente y precisa.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La forma de los datos</span>"
    ]
  },
  {
    "objectID": "060-distr-prob.html",
    "href": "060-distr-prob.html",
    "title": "7  Probabilidad y distribuciones de probabilidad",
    "section": "",
    "text": "7.0.1 ¿Qué es la Probabilidad?\nLa probabilidad es una rama de las matemáticas que se ocupa del estudio de los fenómenos aleatorios y la incertidumbre. Nos ayuda a medir la posibilidad de que ocurran ciertos eventos y a tomar decisiones informadas en situaciones de incertidumbre.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Probabilidad y distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "060-distr-prob.html#frecuencia-relativa-y-probabilidad",
    "href": "060-distr-prob.html#frecuencia-relativa-y-probabilidad",
    "title": "7  Probabilidad y distribuciones de probabilidad",
    "section": "7.1 Frecuencia relativa y probabilidad",
    "text": "7.1 Frecuencia relativa y probabilidad\n\n7.1.1 Frecuencia Relativa\nDefinición: La frecuencia relativa se refiere a la proporción de veces que ocurre un evento en relación con el número total de ensayos o experimentos realizados.\nCálculo: La frecuencia relativa se calcula como: \\[\n\\text{Frecuencia Relativa} = \\frac{\\text{Número de veces que ocurre el evento}}{\\text{Número total de ensayos}}\n\\]\nEjemplo: Si lanzas una moneda 100 veces y obtienes 52 caras, la frecuencia relativa de obtener cara es: \\[\n\\text{Frecuencia Relativa} = \\frac{52}{100} = 0.52\n\\]\nAplicación: La frecuencia relativa se utiliza principalmente en el análisis de datos experimentales y observacionales para estimar la probabilidad empírica de eventos basándose en la evidencia observada.\n\n\n7.1.2 Probabilidad\nDefinición La probabilidad es una medida teórica de la probabilidad de que ocurra un evento, basada en un modelo matemático o un conjunto de supuestos.\nCálculo La probabilidad de un evento \\(A\\), denotada como \\(P(A)\\), se calcula como:\n\\[\nP(A) = \\frac{\\text{Número de casos favorables}}{\\text{Número total de casos posibles}}\n\\]\nEjemplo: Para una moneda justa, la probabilidad de obtener cara es: \\[\nP(\\text{Cara}) = \\frac{1}{2} = 0.5\n\\] Aplicación: La probabilidad se utiliza en teoría de la probabilidad y estadística para predecir la ocurrencia de eventos en base a modelos matemáticos y supuestos teóricos.\n\n\n7.1.3 Comparación\n\n\n\n\n\n\n\n\nCaracterística\nFrecuencia Relativa\nProbabilidad\n\n\n\n\nDefinición\nProporción de veces que ocurre un evento en un número de ensayos\nMedida teórica de la probabilidad de que ocurra un evento\n\n\nCálculo\n\\(\\frac{\\text{Número de veces que ocurre el evento}}{\\text{Número total de ensayos}}\\)\n\\(\\frac{\\text{Número de casos favorables}}{\\text{Número total de casos posibles}}\\)\n\n\nBasado en\nDatos experimentales u observacionales\nModelos matemáticos y supuestos teóricos\n\n\nEjemplo\nFrecuencia relativa de obtener cara en 100 lanzamientos de moneda es \\(0.52\\)\nProbabilidad de obtener cara en una moneda justa es \\(0.5\\)\n\n\nAplicación\nEstimación empírica de probabilidades\nPredicción de eventos basados en modelos teóricos\n\n\n\nEn resumen, la frecuencia relativa se basa en datos observados y se utiliza para estimar probabilidades empíricas, mientras que la probabilidad es una medida teórica basada en modelos matemáticos. Ambas son herramientas útiles en el análisis de datos y la toma de decisiones informadas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Probabilidad y distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "060-distr-prob.html#distribuciones-de-probabilidad",
    "href": "060-distr-prob.html#distribuciones-de-probabilidad",
    "title": "7  Probabilidad y distribuciones de probabilidad",
    "section": "7.2 Distribuciones de probabilidad",
    "text": "7.2 Distribuciones de probabilidad\n\n7.2.1 Distribución normal\ndirtib de frecuencia y distr normal: área bajo la curva\nHow to predict record-shattering weather events | The Economist\n\n\n\nmedia-y-varianza\n\n\nExplained: Sigma | MIT News | Massachusetts Institute of Technology\n\n\n\nimg\n\n\n\n\n7.2.2 Otras distribuciones\n\n\n7.2.3 Gráficos de probabilidad",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Probabilidad y distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "060-distr-prob.html#fútbol",
    "href": "060-distr-prob.html#fútbol",
    "title": "7  Probabilidad y distribuciones de probabilidad",
    "section": "7.3 Fútbol",
    "text": "7.3 Fútbol",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Probabilidad y distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "060-distr-prob.html#proceso-de-dosificación-de-líquidos",
    "href": "060-distr-prob.html#proceso-de-dosificación-de-líquidos",
    "title": "7  Probabilidad y distribuciones de probabilidad",
    "section": "7.4 Proceso de dosificación de líquidos",
    "text": "7.4 Proceso de dosificación de líquidos",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Probabilidad y distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "060-distr-prob.html#ley-de-contenido-efectivo",
    "href": "060-distr-prob.html#ley-de-contenido-efectivo",
    "title": "7  Probabilidad y distribuciones de probabilidad",
    "section": "7.5 Ley de contenido efectivo",
    "text": "7.5 Ley de contenido efectivo",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Probabilidad y distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "070-relacion-xy.html",
    "href": "070-relacion-xy.html",
    "title": "8  La relación entre las variables",
    "section": "",
    "text": "8.1 Diagramas de puntos \\((x,y\\))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>La relación entre las variables</span>"
    ]
  },
  {
    "objectID": "070-relacion-xy.html#correlación",
    "href": "070-relacion-xy.html#correlación",
    "title": "8  La relación entre las variables",
    "section": "8.2 Correlación",
    "text": "8.2 Correlación\n\n8.2.1 Correlación y causalidad\nAnscombe",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>La relación entre las variables</span>"
    ]
  },
  {
    "objectID": "070-relacion-xy.html#tablas-de-asociación",
    "href": "070-relacion-xy.html#tablas-de-asociación",
    "title": "8  La relación entre las variables",
    "section": "8.3 Tablas de asociación",
    "text": "8.3 Tablas de asociación",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>La relación entre las variables</span>"
    ]
  },
  {
    "objectID": "080-anova.html",
    "href": "080-anova.html",
    "title": "9  El análisis de la varianza",
    "section": "",
    "text": "9.1 Introducción\nSupongamos que un analista de la OMS ha realizado la medida de la altura de un grupo de niños y niñas niña siguiendo rigurosamente el método establecido, y, por lo tanto, que está razonablemente seguro de su resultado.\nAl cabo de varias jornadas de trabajo, habrá realizado varias medidas, que representarán al conjunto de niños de la población en la que ha estado trabajando. Otros investigadores pueden haber estado trabajando a la vez en otras poblaciones, y al final de sus jornadas de trabajo, quieren comparar sus resultados: ¿Hay alguna de estas poblaciones en las que los niños sean significativamente más altos (o más bajos) que en las otras? ¿Cómo describir la altura de un conjunto de individuos de manera que se puedan hacer comparaciones con otros conjuntos?\nPara responder a estas preguntas, vamos a cambiar el entorno de trabajo a un grupo de niños imaginario, que vamos a llamar aula1: son nuestros compañeros y compañeras, a los cuales realizaremos una medida de altura siguiendo el procedimiento especificado en nuestro método. ## Análisis de la varianza de un factor",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>El análisis de la varianza</span>"
    ]
  },
  {
    "objectID": "080-anova.html#análisis-de-la-varianza-de-dos-factores",
    "href": "080-anova.html#análisis-de-la-varianza-de-dos-factores",
    "title": "9  El análisis de la varianza",
    "section": "9.2 Análisis de la varianza de dos factores",
    "text": "9.2 Análisis de la varianza de dos factores",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>El análisis de la varianza</span>"
    ]
  },
  {
    "objectID": "080-anova.html#section",
    "href": "080-anova.html#section",
    "title": "9  El análisis de la varianza",
    "section": "9.3 ",
    "text": "9.3",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>El análisis de la varianza</span>"
    ]
  },
  {
    "objectID": "090-sistema-medicion.html",
    "href": "090-sistema-medicion.html",
    "title": "10  El análisis del sistema de medición",
    "section": "",
    "text": "10.1 ¿Qué es una medida?\nUna medida es el resultado de la acción de medir. Normalmente, medir quiere decir comparar lo que va a ser medido con un patrón de referencia; esta comparación es realizada por una o varias personas que llamaremos analistas, los cuales utilizarán un método analítico, siguiendo un procedimiento de medida. Por ejemplo, en la imagen a continuación, la analista está midiendo la altura de un niño utilizando un instrumento de medida, una cinta métrica.\nHasta aquí parece que todo está suficientemente claro, por lo que el resultado de la medida debe ser un valor que no nos ofrecerá dudas sobre su veracidad. Sin embargo, si analizamos el proceso con atención, veremos que hay algunos elementos que pueden hacer que nuestro resultado no sea todo lo preciso que habíamos pensado. Por ejemplo, en la imagen no vemos si el niño está calzado o no. Es evidente que deberíamos decir al analista que el niño debe estar descalzo, ya que diferentes tipos de calzado podrían alterar el resultado de formas diferentes. EL niño podría estar ligeramente encorvado, o sus rodillas dobladas, y entonces la altura que estamos midiendo será menor de la altura real. Además de esto, la forma de realizar la evaluación de la altura se ve influenciada por la posición de los ojos del analista: si están demasiado bajos, no verá correctamente la parte superior de la cabeza y tenderá a sobreestimar el verdadero valor por un efecto de perspectiva. Por otra parte, no sabemos si el instrumento utilizado tiene una escala de medida construida de forma fiable o sólo aproximada. Si nuestro instrumento (la cinta métrica) no es fiable, o su escala difiere de la de otros instrumentos semejantes, es posible que el valor de la medida varíe.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>El análisis del sistema de medición</span>"
    ]
  },
  {
    "objectID": "090-sistema-medicion.html#qué-es-una-medida",
    "href": "090-sistema-medicion.html#qué-es-una-medida",
    "title": "10  El análisis del sistema de medición",
    "section": "",
    "text": "Cinta métrica de sastre\n\n\n\n\nMetro de albañilería",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>El análisis del sistema de medición</span>"
    ]
  },
  {
    "objectID": "090-sistema-medicion.html#los-estándares-de-medida",
    "href": "090-sistema-medicion.html#los-estándares-de-medida",
    "title": "10  El análisis del sistema de medición",
    "section": "10.2 Los estándares de medida",
    "text": "10.2 Los estándares de medida\nPor lo que hemos visto, cuando hacemos una medida, debemos establecer un procedimiento de medida, que debe indicar al analista cual es la forma correcta de realizar los pasos para hacer que la medida sea veraz. Deberemos definir también el instrumento de medida, de manera que cuando se repita el procedimiento no se introduzca un factor de variación debido al uno de un instrumento inapropiado. LO mejor es que este instrumento disponga de una homologación por un servicio de homologación externo, que nos asegure, por ejemplo, que los intervalos de medida de que dispone se corresponden con valores de referencia, en este caso, centímetros y milímetros. El procedimiento debe establecer también con claridad las condiciones en que las debe estar el objeto a medir (la persona, en este caso): descalzo, perfectamente estirado, con sus rodillas rectas, etc. Seguramente, el procedimiento incluirá un dibujo para que el analista visualice con claridad los puntos claves que debe revisar para hacer una buena medida. En el dibujo a continuación, se indican algunos de estos puntos claves, incluyendo la necesidad de que el niño se apoye en un plano vertical (la pared) y que el analista se situe correctamente para que su vista sea perpendicular al plano, utilizando una guía para la valoración correcta de la altura medida.\n\nPero ¿y si la niña tiene una altura tal que el analista no puede mantener una posición estable? El procedimiento real puede llegar a ser mucho más complejo, tal como vemos en el último gráfico, que proviene de un documento médico de la Organización Mundial de la Salud, en donde la correcta estimación del peso y altura de los niños es fundamental para determinar su estado de salud nutricional, y por lo tanto es necesario minimizar el riesgo de errores de medida, garantizando que todos los analistas realizan correctamente el mismo procedimiento aunque estén en diferentes ubicaciones y en momentos diferentes:\n\nEL procedimiento de la OMS ha estimado que es necesario que sean dos los analistas que realizan la medida, utilizando un aparato especialmente diseñado para ello, y que utiliza una pieza para ajustar a la cabeza de manera que la posición de lectura no esté sometida al error de la posición del analista que realiza la medida.\nLa descripción del procedimiento de análisis, junto con el detalle de los instrumentos necesarios y sus homologaciones requeridas, constituye lo que se conoce como método analítico. El analista o analistas deberán estudiar este método analítico para estar seguros de que son capaces de llevarlo a la práctica sin error.\nVeremos en un apartado posterior que cada uno de estos elementos dan lugar a un tipo de error concreto, que son principalmente dos: los debidos al analista y los debidos al procedimiento (incluyendo aquí los errores instrumentales) Veremos cómo evaluar la magnitud de cada uno de estos errores y la forma de establecer un plan de trabajo para reducirlos, mejorando así la calidad de nuestras medidas.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>El análisis del sistema de medición</span>"
    ]
  },
  {
    "objectID": "090-sistema-medicion.html#la-precisión-analítica",
    "href": "090-sistema-medicion.html#la-precisión-analítica",
    "title": "10  El análisis del sistema de medición",
    "section": "10.3 La precisión analítica",
    "text": "10.3 La precisión analítica",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>El análisis del sistema de medición</span>"
    ]
  },
  {
    "objectID": "090-sistema-medicion.html#análisis-de-repetibilidad-y-reproducibilidad-grr-analysis",
    "href": "090-sistema-medicion.html#análisis-de-repetibilidad-y-reproducibilidad-grr-analysis",
    "title": "10  El análisis del sistema de medición",
    "section": "10.4 Análisis de repetibilidad y reproducibilidad (GR&R analysis)",
    "text": "10.4 Análisis de repetibilidad y reproducibilidad (GR&R analysis)\n\n10.4.1 Round only on the final calculation result[edit]\nWhen performing multiple stage calculations, do not round intermediate stage calculation results; keep as many digits as is practical (at least one more digit than the rounding rule allows per stage) until the end of all the calculations to avoid cumulative rounding errors while tracking or recording the significant figures in each intermediate result. Then, round the final result, for example, to the fewest number of significant figures (for multiplication or division) or leftmost last significant digit position (for addition or subtraction) among the inputs in the final calculation.[15]\n\n(2.3494 + 1.345) × 1.2 = 3.6944 × 1.2 = 4.43328 ≈ 4.4.\n(2.3494 × 1.345) + 1.2 = 3.159943 + 1.2 = 4.359943 ≈ 4.4.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>El análisis del sistema de medición</span>"
    ]
  },
  {
    "objectID": "090-sistema-medicion.html#precision-of-measuring-tools-and-significant-figures",
    "href": "090-sistema-medicion.html#precision-of-measuring-tools-and-significant-figures",
    "title": "10  El análisis del sistema de medición",
    "section": "10.5 Precision of Measuring Tools and Significant Figures",
    "text": "10.5 Precision of Measuring Tools and Significant Figures\nAccuracy, Precision, and Significant Figures | Physics (lumenlearning.com)\nAn important factor in the accuracy and precision of measurements involves the precision of the measuring tool. In general, a precise measuring tool is one that can measure values in very small increments. For example, a standard ruler can measure length to the nearest millimeter, while a caliper can measure length to the nearest 0.01 millimeter. The caliper is a more precise measuring tool because it can measure extremely small differences in length. The more precise the measuring tool, the more precise and accurate the measurements can be.\nWhen we express measured values, we can only list as many digits as we initially measured with our measuring tool. For example, if you use a standard ruler to measure the length of a stick, you may measure it to be 36.7 cm. You could not express this value as 36.71 cm because your measuring tool was not precise enough to measure a hundredth of a centimeter. It should be noted that the last digit in a measured value has been estimated in some way by the person performing the measurement. For example, the person measuring the length of a stick with a ruler notices that the stick length seems to be somewhere in between 36.6 cm and 36.7 cm, and he or she must estimate the value of the last digit. Using the method of significant figures, the rule is that the last digit written down in a measurement is the first digit with some uncertainty. In order to determine the number of significant digits in a value, start with the first measured value at the left and count the number of digits through the last digit written on the right. For example, the measured value 36.7cm has three digits, or significant figures. Significant figures indicate the precision of a measuring tool that was used to measure a value.\n\n10.5.1 La “mano del quesero”\nComparar pros y contras de la práctica basada en la experiencia con la práctica basada ne el método y la cuantificación\n\nsubjetividad\npérdida de conocimiento si el experto deja la empresa\n\n\n\n10.5.2 Método cientifico\nAlgoritmos - recetas cocina- DMAIC - método cientifico\nMontgomery 1.1\nLa reproducibilidad de los análisis de datos\nLiterate programming - Wikipedia\nReproducible Research (hbiostat.org)\nrr (hbiostat.org)\nEn el mundo científico y técnico cada vez cobra más importancia el concepto de reproducibilidad de los análisis, sobre todo cuando se trata de comunicar o publicar el resultado de un trabajo o de una investigación. Medios, como la prestigiosa revista Science, se han hecho eco de ello (Buck 2015). Por otra parte, la utilización de un flujo de trabajo basado en hojas de cálculo hace difícil garantizar esta reproducibilidad, y a veces puede llevar a cometer errores de consecuencias graves (Ferrero 2018; Ryssdal 2013).\nJesse Sadler (Sadler 2017) lo explica así:\nEl peligro de la hoja de cálculo deriva de su propia estructura. La mezcla de entrada de datos, análisis y visualización hace que sea fácil confundir las celdas que contienen datos sin procesar con las que son el resultado del análisis. La forma de definir la lógica programática, tal como la selección de qué celdas se van a sumar, mediante clics del mouse, significa que una acción errónea de clic o arrastre puede provocar errores o la sobreescritura de datos. Solo hace falta pensar en el pavor del momento en el que vas a cerrar una hoja de cálculo y el programa te pregunta si te gustaría guardar los cambios. Te hace preguntarte. ¿Quiero guardar? ¿Qué cambios hice? Debido a que la lógica en una hoja de cálculo se realiza a través de clics del mouse, no hay forma de rastrear de manera efectiva qué cambios se han realizado en una sesión o en la producción de un gráfico. Los errores cometidos con Excel pueden tener consecuencias graves, como se puso de manifiesto tras la controversia alrededor del artículo de Carmen Reinhart y Kenneth Rogoff sobre la deuda nacional de los EEUU.\nCiertamente hay razones legítimas por las que las personas usan por defecto hojas de cálculo para el análisis de datos en lugar de usar un lenguaje de programación como R. Las hojas de cálculo son mucho más atractivas y confortables de lo que cualquier lenguaje de programación podría ser para un recién llegado. Aprender a programar es intimidante y no es algo que se pueda hacer rápida o fácilmente. Las aplicaciones de interfaz gráfica de usuario (GUI) son mucho menos desalentadoras que una interfaz de línea de comandos. En segundo lugar, las hojas de cálculo son una buena herramienta para la entrada de datos, y es tentador pasar directamente al análisis de datos, manteniendo todo en el mismo documento. Finalmente, la naturaleza interactiva de las hojas de cálculo y la capacidad de crear gráficos que cambian en función de las entradas es muy atractiva, incluso si desbloquear completamente este potencial implica un conocimiento bastante complejo sobre cómo funciona el programa. La primera ventaja de las hojas de cálculo sobre la programación no se supera fácilmente, pero las dos últimas se basan en lo que creo que es un flujo de trabajo problemático. En lugar de usar un par de aplicaciones monolíticas, a menudo un conjunto de aplicaciones de oficina, para hacer todo, creo que es mejor dividir el flujo de trabajo entre varias aplicaciones que hacen una cosa bien.\nCrear una división clara entre la entrada y el análisis de datos es una de las principales razones por las que el análisis de datos en un lenguaje de programación es preferible al software de hoja de cálculo. Todavía uso hojas de cálculo, pero su limito su uso estrictamente a la entrada de datos. En un programa de hoja de cálculo, el análisis manipula directamente la única copia de los datos sin procesar. Por el contrario, con R se importan los datos, creando un objeto que es una copia de los datos sin procesar. Todas las manipulaciones de los datos se realizan en esta copia, y los datos originales nunca se alteran de ninguna manera. Esto significa que no hay forma de estropear los datos sin procesar. La manipulación de una copia de los datos le permite experimentar más libremente. Los errores son intrascendentes, incluso aunque a veces puedan llegar a ser frustrantes. Una línea de código que devuelve un error se puede ajustar y volver a ejecutar, repitiendo el proceso las veces necesarias hasta que se devuelva el resultado esperado.\nTrabajar en una copia de los datos sin procesar puede incluso simplificar el proceso de entrada de datos. El análisis de datos tabulares en R da como resultado la creación de múltiples objetos, que se conocen como data frames y pueden considerarse equivalentes a tablas en una hoja de cálculo. La capacidad de dividir, muestrear y transformar el conjunto de datos original en muchos data frames diferentes tiene la ventaja de reducir drásticamente la complejidad de la entrada de datos. En lugar de necesitar hojas de cálculo a medida con múltiples hojas y tablas interrelacionadas, cada pieza de datos solo debe ingresarse una vez y todas las manipulaciones se pueden realizar en el código. Los diferentes data frames que se crean en el proceso de análisis ni siquiera tienen que ser guardados, porque son muy fácilmente reproducidos por el script de código.\nLa separación de la entrada y el análisis de los datos reduce en gran manera el potencial de errores, pero tal vez aún más significativamente, el uso de código para el análisis de datos permite la creación de investigaciones reproducibles que no son posibles en hojas de cálculo. […] Con un lenguaje de programación, los pasos del análisis se pueden establecer claramente en el código […] Guardar el análisis en código tiene el beneficio inmediato de que se puede volver a ejecutar fácilmente en cualquier momento que se agreguen nuevos datos. El código también se puede aplicar a un conjunto de datos completamente nuevo de una manera mucho más transparente que con las hojas de cálculo. El beneficio a largo plazo es que con el código todo el análisis se documenta en lugar de ocultarse detrás de los clics del mouse. Esto hace que sea más fácil revisar los propios análisis mucho después de haber terminado con ellos, así como que otros entiendan lo que se ha hecho y comprueben si hay errores.\n\n\n\n\nBuck, Stuart. 2015. “Solving Reproducibility.” Science 348 (6242): 1403. https://www.science.org/doi/full/10.1126/science.aac8041.\n\n\nFerrero, Rosana. 2018. “Los Errores de Reinhart & Rogoff: R y La Reproducibilidad.” 2018. https://www.maximaformacion.es/blog-dat/los-errores-de-reinhart-rogo/.\n\n\nRyssdal, Karl. 2013. “The Excel Mistake Heard Round the World.” 2013. https://www.marketplace.org/2013/04/17/economy/excel-mistake-heard-round-world/.\n\n\nSadler, Jesse. 2017. “Excel Vs r: A Brief Introduction to r.” 2017. https://www.jessesadler.com/post/excel-vs-r/.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>El análisis del sistema de medición</span>"
    ]
  },
  {
    "objectID": "100-control-proc.html",
    "href": "100-control-proc.html",
    "title": "11  El control estadístico de procesos",
    "section": "",
    "text": "11.1 La mejora de la calidad y el control estadístico de procesos",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>El control estadístico de procesos</span>"
    ]
  },
  {
    "objectID": "100-control-proc.html#introducción-a-los-gráficos-de-control",
    "href": "100-control-proc.html#introducción-a-los-gráficos-de-control",
    "title": "11  El control estadístico de procesos",
    "section": "11.2 Introducción a los gráficos de control",
    "text": "11.2 Introducción a los gráficos de control\n\n11.2.1 Causas comunes y causas especiales de variación\n\n\n11.2.2 Variación a corto plazo y variación a largo plazo",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>El control estadístico de procesos</span>"
    ]
  },
  {
    "objectID": "100-control-proc.html#la-capacidad-de-un-proceso",
    "href": "100-control-proc.html#la-capacidad-de-un-proceso",
    "title": "11  El control estadístico de procesos",
    "section": "11.3 La capacidad de un proceso",
    "text": "11.3 La capacidad de un proceso",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>El control estadístico de procesos</span>"
    ]
  },
  {
    "objectID": "100-control-proc.html#ejemplo-establecer-las-especificaciones-de-un-producto",
    "href": "100-control-proc.html#ejemplo-establecer-las-especificaciones-de-un-producto",
    "title": "11  El control estadístico de procesos",
    "section": "11.4 Ejemplo: establecer las especificaciones de un producto",
    "text": "11.4 Ejemplo: establecer las especificaciones de un producto",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>El control estadístico de procesos</span>"
    ]
  },
  {
    "objectID": "110-disexp.html",
    "href": "110-disexp.html",
    "title": "12  Diseño de experimentos",
    "section": "",
    "text": "12.1 Experimentos factoriales\n¿La aspirina reduce el riesgo de infarto? ¿Una marca de abono es más eficaz para el cultivo de rosas que otra? ¿El cansancio es tan peligroso para un conductor como la influencia del alcohol? Este tipo de preguntas se responden con experimentos aleatorios.\nEl propósito de un experimento es investigar la relación entre dos o más variables. Cuando una variable provoca un cambio en otra, llamamos a la primera variable la variable independiente o explicativa. La variable afectada se llama variable dependiente o variable de respuesta: estímulo, respuesta. En un experimento aleatorio, el investigador manipula los valores de la variable explicativa y mide los cambios resultantes en la variable de respuesta. Los diferentes valores de la variable explicativa se denominan tratamientos. Una unidad experimental es un único objeto o persona que se va a medir.\nSupongamos que usted quiere investigar la eficacia de la vitamina E en la prevención de enfermedades. Usted recluta a un grupo de sujetos y les pregunta si toman regularmente vitamina E. Observa que los sujetos que toman vitamina E, en promedio, presentan una salud mejor que quienes no la toman. ¿Esto prueba que la vitamina E es eficaz en la prevención de enfermedades? No es así. Hay muchas diferencias entre los dos grupos comparados, además del consumo de vitamina E. Las personas que toman vitamina E con regularidad suelen tomar otras medidas para mejorar su salud: ejercicio, dieta, otros suplementos vitamínicos, elección de no fumar, etc. Cualquiera de estos factores podría estar influyendo en la salud. Como se ha descrito, este estudio no demuestra que la vitamina E sea la clave para la prevención de enfermedades.\nLas variables adicionales que pueden enturbiar un estudio se denominan variables ocultas. Para demostrar que la variable explicativa provoca un cambio en la variable de respuesta, es necesario aislar la variable explicativa. La investigadora debe diseñar su experimento de forma que solo haya una diferencia entre los grupos que se comparan: los tratamientos previstos. Esto se consigue mediante la asignación aleatoria de unidades experimentales a grupos de tratamiento. Cuando los sujetos se asignan a los tratamientos de forma aleatoria, todas las variables ocultas potenciales se reparten por igual entre los grupos. En este punto, la única diferencia entre los grupos es la impuesta por el investigador. Los diferentes resultados medidos en la variable de respuesta, por tanto, deben ser una consecuencia directa de los diferentes tratamientos. De este modo, un experimento puede demostrar una conexión causa-efecto entre las variables explicativas y las de respuesta.\nEl poder de la sugestión puede tener una importante influencia en el resultado de un experimento. Los estudios han demostrado que la expectativa del participante en el estudio puede ser tan importante como el medicamento real. En un estudio sobre fármacos que mejoran el desempeño, los investigadores señalaron:\nCuando la participación en un estudio provoca una respuesta física del participante, es difícil aislar los efectos de la variable explicativa. Para contrarrestar el poder de la sugestión, los investigadores reservaron un grupo de tratamiento como grupo de control . Este grupo recibe un tratamiento placebo, es decir, un tratamiento que no puede influir en la variable de respuesta. El grupo de control ayuda a los investigadores a equilibrar los efectos de estar en un experimento con los efectos de los tratamientos activos. Por supuesto, si usted participa en un estudio y sabe que está recibiendo una píldora que no contiene ningún medicamento real, entonces el poder de la sugestión ya no es un factor. Que un experimento aleatorio sea ciego preserva el poder de la sugestión. Cuando una persona participa en un estudio de investigación ciego, no sabe quién recibe el tratamiento activo y quién el placebo. Un experimento doble ciego es aquel en el que tanto los sujetos como los investigadores que participan en él no conocen la información del fármaco.\nNo un factyor de cada vez - explciar interaccion",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Diseño de experimentos</span>"
    ]
  },
  {
    "objectID": "120-mejora-calidad.html",
    "href": "120-mejora-calidad.html",
    "title": "13  La calidad y la mejora de la calidad",
    "section": "",
    "text": "13.1 Six Sigma y mejora de la calidad",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La calidad y la mejora de la calidad</span>"
    ]
  },
  {
    "objectID": "120-mejora-calidad.html#definir-un-problema-opex-lean-sixsigma-16",
    "href": "120-mejora-calidad.html#definir-un-problema-opex-lean-sixsigma-16",
    "title": "13  La calidad y la mejora de la calidad",
    "section": "13.2 Definir un problema [OPEX Lean SixSigma #16]",
    "text": "13.2 Definir un problema [OPEX Lean SixSigma #16]\n\n13.2.1 ¿Cómo es una buena definición de un problema?\n\nBreve\nEvitar lenguaje técnico: debes ser capaz de explicarlo a cualquier persona de la organización usando términos sencillos\nCuantificar el problema, usando los datos disponibles\nIntegra y explica el coste real del problema, para justificar la necesidad del análisis. Puedes relacionarlo con los costes de no calidad\nDefine el ámbito del problema: usa los términos que sean necesarios para delimitarlo con precisión.\nLa definición de un problema debe conseguir formularlo de forma que sea específico, medible, realizable, relevante y acotado en el tiempo (plazo)",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La calidad y la mejora de la calidad</span>"
    ]
  },
  {
    "objectID": "120-mejora-calidad.html#estrategia-de-resolucion-de-problemas",
    "href": "120-mejora-calidad.html#estrategia-de-resolucion-de-problemas",
    "title": "13  La calidad y la mejora de la calidad",
    "section": "13.3 Estrategia de resolucion de problemas",
    "text": "13.3 Estrategia de resolucion de problemas",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La calidad y la mejora de la calidad</span>"
    ]
  },
  {
    "objectID": "120-mejora-calidad.html#dmaic---sixsigma",
    "href": "120-mejora-calidad.html#dmaic---sixsigma",
    "title": "13  La calidad y la mejora de la calidad",
    "section": "13.4 DMAIC - SixSigma",
    "text": "13.4 DMAIC - SixSigma",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La calidad y la mejora de la calidad</span>"
    ]
  },
  {
    "objectID": "120-mejora-calidad.html#el-papel-de-los-métodos-estadísticos-en-la-mejora-six-sigma",
    "href": "120-mejora-calidad.html#el-papel-de-los-métodos-estadísticos-en-la-mejora-six-sigma",
    "title": "13  La calidad y la mejora de la calidad",
    "section": "13.5 El papel de los métodos estadísticos en la mejora Six Sigma",
    "text": "13.5 El papel de los métodos estadísticos en la mejora Six Sigma",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La calidad y la mejora de la calidad</span>"
    ]
  },
  {
    "objectID": "130-comunicacion.html",
    "href": "130-comunicacion.html",
    "title": "14  La comunicación",
    "section": "",
    "text": "quarto markdown PowerPoint Gráficos",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>La comunicación</span>"
    ]
  },
  {
    "objectID": "140-anexo-R.html",
    "href": "140-anexo-R.html",
    "title": "Anexo: Instalación de R y conceptos básicos",
    "section": "",
    "text": "Instalación de R en Windows",
    "crumbs": [
      "Anexo: Instalación de R y conceptos básicos"
    ]
  },
  {
    "objectID": "140-anexo-R.html#instalación-de-r-en-windows",
    "href": "140-anexo-R.html#instalación-de-r-en-windows",
    "title": "Anexo: Instalación de R y conceptos básicos",
    "section": "",
    "text": "Accede al sitio oficial de CRAN (Comprehensive R Archive Network), que es el repositorio central de software de R⁴.\nHaz clic en el enlace “Download R for Windows”.\nSelecciona “install R for the first time” en la parte superior de la página.\nElige la versión de R que deseas instalar (por ejemplo, R 4.0.3).\nGuarda el archivo ejecutable en tu computadora (puedes guardarlo en el escritorio).\nHaz doble clic en el archivo descargado para ejecutarlo.\nAcepta los permisos para que la aplicación realice cambios en tu dispositivo.\nSelecciona el idioma de tu preferencia y sigue las opciones de instalación (puedes aceptar las opciones preestablecidas).",
    "crumbs": [
      "Anexo: Instalación de R y conceptos básicos"
    ]
  },
  {
    "objectID": "140-anexo-R.html#instalación-de-rstudio-en-windows",
    "href": "140-anexo-R.html#instalación-de-rstudio-en-windows",
    "title": "Anexo: Instalación de R y conceptos básicos",
    "section": "Instalación de RStudio en Windows",
    "text": "Instalación de RStudio en Windows\n\nAbre tu navegador y dirígete al sitio oficial de RStudio.\nHaz clic en “DOWNLOAD”.\nBusca la opción “RStudio Desktop” y selecciona “DOWNLOAD”.\nHaz clic en “DOWNLOAD RSTUDIO FOR WINDOWS”.\nGuarda el archivo ejecutable.\nEjecuta el archivo descargado y sigue las instrucciones de instalación.",
    "crumbs": [
      "Anexo: Instalación de R y conceptos básicos"
    ]
  },
  {
    "objectID": "140-anexo-R.html#introducción-a-r",
    "href": "140-anexo-R.html#introducción-a-r",
    "title": "Anexo: Instalación de R y conceptos básicos",
    "section": "Introducción a R",
    "text": "Introducción a R\n\nTipos de datos en R\n\nNumérico (numeric):\n\nRepresenta valores decimales, tanto enteros como de punto flotante (double).\nEjemplo: 3.14, 42, 0.5.\n\nEntero (integer):\n\nRepresenta números enteros.\nEjemplo: 5, -10, 100.\n\nLógico (logical):\n\nRepresenta valores booleanos: TRUE o FALSE.\nEjemplo: TRUE, FALSE.\n\nCarácter (character):\n\nRepresenta cadenas de texto.\nEjemplo: \"Hola, mundo\", \"R es genial\".\n\nComplejo (complex):\n\nRepresenta números complejos con parte real e imaginaria.\nEjemplo: 1 + 2i, 3 - 4i.\n\nRaw:\n\nRepresenta datos en formato binario sin procesar.\nEjemplo: as.raw(0:5) (crea un vector de bytes).\n\n\n\n\nVectores\nEn R, un vector es una estructura de datos fundamental que almacena elementos del mismo tipo, ya sean números, caracteres o lógicos². Aquí tienes una breve explicación:\n\n¿Qué es un vector en R?\n\nUn vector es una secuencia de elementos de datos del mismo tipo básico.\nLos miembros de un vector se llaman oficialmente componentes.\nPueden ser de dos tipos: vectores atómicos y listas².\n\n\nLos vectores atómicos son los más comunes y se utilizan para almacenar datos homogéneos. Algunos ejemplos de vectores atómicos incluyen:\n\nNuméricos (numeric):\n\nRepresentan valores decimales, tanto enteros como de punto flotante.\nEjemplo: c(3.14, 42, 0.5).\n\nCaracteres (character):\n\nAlmacenan cadenas de texto.\nEjemplo: c(\"Hola\", \"Mundo\").\n\nLógicos (logical):\n\nContienen valores booleanos: TRUE o FALSE.\nEjemplo: c(TRUE, FALSE, TRUE).\n\nEnteros (integer):\n\nRepresentan números enteros.\nEjemplo: c(5, -10, 100).\n\n\nLos vectores son fundamentales para realizar operaciones matemáticas, análisis de datos y manipulación de información en R.\n\nEjemplos de creación de vectores en R\nLos vectores en R pueden contener datos del mismo tipo y se crean utilizando la función c().\n\nVectores numéricos:\n\nPuedes crear un vector numérico utilizando la función c():\nnumeros &lt;- c(1, 2, 3, 4, 5)\nEsto crea un vector con los números del 1 al 5.\n\nVectores de caracteres:\n\nPara crear un vector de caracteres, simplemente proporciona las cadenas de texto entre comillas:\nfrutas &lt;- c(\"manzana\", \"banana\", \"cereza\")\nEsto crea un vector con los nombres de algunas frutas.\n\nVectores lógicos:\n\nLos vectores lógicos contienen valores TRUE o FALSE. Puedes crear uno así:\nlogico &lt;- c(TRUE, FALSE, TRUE)\nEsto crea un vector con tres valores lógicos.\n\nVectores con nombres:\n\nPuedes asignar nombres a los elementos de un vector:\nmi_vector &lt;- c(naranja = 4, manzana = 6)\nEsto crea un vector con dos elementos nombrados: “naranja” y “manzana”.\n\nData frames:\n\nIntroduce los data frames como tablas de datos con filas y columnas.\nExplica cómo crear, acceder y modificar data frames.\nDestaca la importancia de los data frames para el análisis de datos.\n\n\nUn data frame en R es una estructura de datos bidimensional que se utiliza para almacenar información tabular. Es similar a una tabla o una hoja de cálculo, donde cada columna puede contener diferentes tipos de datos (números, cadenas de texto, etc.). Los data frames son muy útiles para trabajar con datos estructurados en R. Puedes acceder a las columnas y realizar análisis estadísticos sobre ellos.\nAquí tienes una descripción más detallada y algunos ejemplos:\n\nConcepto de Data Frame:\n\nUn data frame es una estructura especializada de tipo lista en R.\nCada componente del data frame tiene la misma longitud y forma una columna.\nLos componentes individuales forman las filas del data frame.\nPuedes pensar en un data frame como una matriz donde cada columna puede contener diferentes tipos de datos¹.\n\nEjemplo de Creación de Data Frame desde Vectores:\n\nPuedes crear un data frame utilizando la función data.frame().\nPor ejemplo, consideremos los siguientes datos:\nName &lt;- c(\"Jon\", \"Bill\", \"Maria\", \"Ben\", \"Tina\")\nAge &lt;- c(23, 41, 32, 58, 26)\ndf &lt;- data.frame(Name, Age)\nprint(df)\nEsto creará un data frame con dos columnas: “Name” y “Age”. Los valores coincidirán con los datos proporcionados.\n\nEjemplo de Creación de Data Frame desde una Matriz:\n\nTambién puedes crear un data frame a partir de una matriz existente.\nSupongamos que tenemos una matriz llamada my_matrix:\nmy_matrix &lt;- matrix(c(1, 2, 3, 4, 5, 6), ncol = 2)\ndf_from_matrix &lt;- data.frame(my_matrix)\nprint(df_from_matrix)\nEsto convertirá la matriz en un data frame con dos columnas.\n\nEjemplo de Creación de Data Frame desde Valores Iniciales:\n\nSi deseas crear un data frame con valores específicos, puedes hacerlo directamente:\ndf_custom &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Carol\"),\n  Age = c(30, 25, 28)\n)\nprint(df_custom)\nEsto creará un data frame personalizado con los valores proporcionados.\n\nEjemplo de Creación de Data Frame Vacío con Nombres de Columna:\n\nSi necesitas un data frame vacío con nombres de columna, puedes hacerlo así:\nempty_df &lt;- data.frame(Name = character(0), Age = numeric(0))\nprint(empty_df)\nEsto crea un data frame sin filas pero con las columnas “Name” y “Age”.\n\n\n\n\n\nCreación de un dataframe a partir de un fichero CSV\ncrear un data frame en R a partir de la lectura de un archivo CSV es una tarea común. Aquí tienes los pasos para hacerlo:\n\nLeer el archivo CSV:\n\nPrimero, necesitas tener un archivo CSV con los datos que deseas cargar en un data frame.\nUtiliza la función read.csv() para leer el archivo CSV y convertirlo en un data frame. Por ejemplo:\nmi_data_frame &lt;- read.csv(\"ruta/al/archivo.csv\")\nReemplaza \"ruta/al/archivo.csv\" con la ubicación real de tu archivo CSV.\n\nExplorar el data frame:\n\nUna vez que hayas leído el archivo, puedes explorar el contenido del data frame utilizando funciones como head(mi_data_frame) para ver las primeras filas o summary(mi_data_frame) para obtener estadísticas resumidas.\n\nAcceder a los datos:\n\nPuedes acceder a las columnas del data frame utilizando el operador $. Por ejemplo:\nprimera_columna &lt;- mi_data_frame$NombreColumna\n\nManipular los datos:\n\nPuedes realizar operaciones, filtrar filas y modificar los valores en el data frame según tus necesidades.\n\nGuardar cambios:\n\nSi realizas modificaciones en el data frame, puedes guardar los cambios en un nuevo archivo CSV utilizando la función write.csv():\nwrite.csv(mi_data_frame, \"ruta/nuevo_archivo.csv\", row.names = FALSE)\nEsto creará un nuevo archivo CSV con los datos actualizados.\n\n\nRecuerda adaptar los nombres de las columnas y las rutas de los archivos según tu caso específico.\n\nVisualización de datos:\n\nMenciona la importancia de la visualización en el análisis estadístico.\nSi hay tiempo, muestra cómo crear gráficos básicos con R (histogramas, scatter plots, etc.).\n\n\n¡Por supuesto! La visualización de datos es fundamental en el análisis de datos, y R ofrece varias opciones para crear gráficos. Aquí te presento una breve descripción y ejemplos de cómo utilizar tanto el programa base como la biblioteca ggplot2 del paquete tidyverse:\n\nPrograma Base de R:\n\nEl programa base de R proporciona funciones para crear gráficos básicos directamente desde los datos.\nAlgunos ejemplos de gráficos básicos son:\n\nGráfico de dispersión:\n# Crear un gráfico de dispersión\nplot(mpg$displ, mpg$hwy, main = \"Consumo de combustible\", xlab = \"Desplazamiento\", ylab = \"Millas por galón\")\nHistograma:\n# Crear un histograma\nhist(mpg$hwy, main = \"Distribución de millas por galón\", xlab = \"Millas por galón\")\nGráfico de barras:\n# Crear un gráfico de barras\nbarplot(table(mpg$class), main = \"Distribución de clases de vehículos\", xlab = \"Clase\", ylab = \"Frecuencia\")\n\n\nBiblioteca ggplot2:\n\nggplot2 es una poderosa biblioteca para crear gráficos basada en la “Gramática de Gráficos”.\nAquí tienes un ejemplo de cómo crear un gráfico de dispersión utilizando ggplot2:\nlibrary(ggplot2)\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point() +\n  labs(title = \"Consumo de combustible\", x = \"Desplazamiento\", y = \"Millas por galón\")\nEn este ejemplo, aes() define las variables estéticas (mapeo de datos a elementos visuales), geom_point() agrega los puntos al gráfico y labs() establece etiquetas para el título y los ejes.\n\nVentajas de ggplot2:\n\nDeclarativo: Describe lo que deseas visualizar y ggplot2 se encarga de los detalles.\nCapas: Puedes agregar capas (geometrías, escalas, facetas) para personalizar tus gráficos.\nEcosistema rico: ggplot2 tiene muchas extensiones y opciones para gráficos más avanzados¹.\n\n\nRecuerda que ggplot2 es especialmente útil para crear gráficos más complejos y personalizados. Si tienes más preguntas, no dudes en preguntar. 😊\nLa visualización de datos es una faceta esencial en el campo de la estadística industrial. Permite convertir conjuntos de datos complejos en representaciones visuales accesibles y fáciles de interpretar. Aquí te explico por qué es tan relevante:\n\nComunicación efectiva:\n\nLa visualización gráfica permite comunicar hallazgos y resultados de manera más clara y efectiva.\nLos gráficos y diagramas facilitan la comprensión de patrones, tendencias y relaciones entre variables.\n\nIdentificación de patrones:\n\nAl visualizar datos, es más sencillo detectar patrones ocultos o anómalos.\nLos gráficos pueden revelar información valiosa sobre procesos industriales, como fluctuaciones en la producción o tendencias en la calidad del producto.\n\nToma de decisiones informada:\n\nLos líderes y analistas industriales pueden tomar decisiones basadas en evidencia visual.\nLa visualización ayuda a evaluar el rendimiento de la producción, identificar áreas de mejora y optimizar procesos.\n\n\nEn la estadística industrial, la visualización de datos es crucial para comprender patrones, tendencias y relaciones en los procesos de producción. R, como lenguaje estadístico, ofrece varias herramientas poderosas para crear gráficos y representaciones visuales. A continuación, menciono algunas de las más útiles:\n\nggplot2:\n\nggplot2 es una biblioteca ampliamente utilizada para la visualización de datos en R.\nSe basa en la “Gramática de Gráficos”, lo que permite crear gráficos personalizados y versátiles.\nEjemplo de uso:\nlibrary(ggplot2)\nggplot(datos, aes(x = variable1, y = variable2)) +\n  geom_point() +\n  labs(title = \"Relación entre dos variables\")\nEn este ejemplo, aes() define las variables estéticas, geom_point() agrega puntos al gráfico y labs() establece etiquetas para el título y los ejes².\n\nPaquete base de R:\n\nR tiene funciones básicas para gráficos, como plot, hist, boxplot, entre otras.\nEstas funciones son parte del paquete base y son útiles para gráficos simples.\nEjemplo de uso:\nplot(datos$variable1, datos$variable2, main = \"Gráfico de dispersión\")\nEsto crea un gráfico de dispersión entre dos variables¹.\n\nGalería de gráficos de R:\n\nLa Galería de gráficos de R es una colección de ejemplos reproducibles creados en R.\nMuestra cientos de gráficos con su código disponible para aprender y adaptar.\nPuedes explorar diferentes tipos de gráficos y encontrar inspiración para tus propios análisis¹.\n\n\n\n\nLas funciones en R\nLas funciones en R son bloques de código que realizan tareas específicas y se pueden reutilizar en diferentes partes de un programa. Aquí tienes una breve descripción y algunos ejemplos:\n\nSintaxis Básica de una Función en R:\n\nPara crear una función en R, utilizamos la siguiente sintaxis:\nnombre_funcion &lt;- function(arg1, arg2, ...) {\n  # Código\n}\n\nnombre_funcion: El nombre que le das a tu función.\narg1, arg2, …: Los argumentos de entrada que la función acepta.\n# Código: El bloque de código que realiza la tarea deseada.\n\n\nEjemplo de Función en R:\n\nSupongamos que queremos calcular el término general de una progresión geométrica.\nCreamos la función an que calcula el término general:\nan &lt;- function(a1, r, n) {\n  a1 * r^(n - 1)\n}\n\na1: Primer término.\nr: Razón o ratio.\nn: Número de términos.\n\nEjemplos de uso:\nan(a1 = 1, r = 2, n = 5)  # Resultado: 16\nan(a1 = 4, r = -2, n = 6)  # Resultado: -128\n\nFunciones Integradas en R:\n\nR tiene muchas funciones incorporadas, como print(), min(), max(), sum(), etc.\nPor ejemplo:\nprint(\"¡Hola, mundo!\")\nmin(1, 2, 3)  # Resultado: 1\nsum(1:5)  # Resultado: 15\nLas funciones en R te permiten modularizar tu código y reutilizarlo.",
    "crumbs": [
      "Anexo: Instalación de R y conceptos básicos"
    ]
  },
  {
    "objectID": "150-bibliografia.html",
    "href": "150-bibliografia.html",
    "title": "Bibliografía",
    "section": "",
    "text": "Buck, Stuart. 2015. “Solving Reproducibility.”\nScience 348 (6242): 1403. https://www.science.org/doi/full/10.1126/science.aac8041.\n\n\nDouglas C Montgomery, Norma Faris Hubele, George C Runger. 2011.\nEngineering Statistics. 111 River Street, Hoboken, NJ\n07030-5774: John Wiley & Sons, Inc.\n\n\nFerrero, Rosana. 2018. “Los Errores de Reinhart & Rogoff: R y\nLa Reproducibilidad.” 2018. https://www.maximaformacion.es/blog-dat/los-errores-de-reinhart-rogo/.\n\n\nHadley Wickham, Garret Grolemund. 2023. “R Para Ciencia de\nDatos.” 2023. https://es.r4ds.hadley.nz/.\n\n\nHadley Wickham, Garret Grolemund, Mine Çetinkaya-Rundel. 2023. R for\nData Science, 2nd Ed. 1005 Gravenstein Highway North, Sebastopol,\nCA95472: O’Reilly Media Inc. https://r4ds.hadley.nz/.\n\n\nRyssdal, Karl. 2013. “The Excel Mistake Heard Round the\nWorld.” 2013. https://www.marketplace.org/2013/04/17/economy/excel-mistake-heard-round-world/.\n\n\nSadler, Jesse. 2017. “Excel Vs r: A Brief Introduction to\nr.” 2017. https://www.jessesadler.com/post/excel-vs-r/.\n\n\nWorld Economic Forum. 2023. “Future of Jobs Report, 2023.”\n91-93 route de la Capite,CH-1223 Cologny/Geneva, Switzerland: World\nEconomic Forum. https://www.weforum.org/publications/the-future-of-jobs-report-2023/.",
    "crumbs": [
      "Bibliografía"
    ]
  }
]